{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"MLBox \u00b6 This is the MLBox Prototype. This is still under construction, some parts probably don't work yet, or may have unexpected/inconsistent behaviours. Get MLBox \u00b6 Installing \u00b6 Install from PyPI: pip install mlcommons-box To uninstall: pip uninstall mlcommons_box Usage Examples \u00b6 Check out the examples directory for detailed examples. License \u00b6 mlperf/mlbox is licensed under the Apache License 2.0. See https://github.com/mlperf/mlbox/blob/master/LICENSE for more information Support \u00b6 Create an issue https://github.com/mlperf/mlbox/issues/new/choose","title":"Home"},{"location":"#mlbox","text":"This is the MLBox Prototype. This is still under construction, some parts probably don't work yet, or may have unexpected/inconsistent behaviours.","title":"MLBox"},{"location":"#get-mlbox","text":"","title":"Get MLBox"},{"location":"#installing","text":"Install from PyPI: pip install mlcommons-box To uninstall: pip uninstall mlcommons_box","title":"Installing"},{"location":"#usage-examples","text":"Check out the examples directory for detailed examples.","title":"Usage Examples"},{"location":"#license","text":"mlperf/mlbox is licensed under the Apache License 2.0. See https://github.com/mlperf/mlbox/blob/master/LICENSE for more information","title":"License"},{"location":"#support","text":"Create an issue https://github.com/mlperf/mlbox/issues/new/choose","title":"Support"},{"location":"getting-started/","text":"Getting Started \u00b6 This section describes some of the example MLCommon-Box boxes, in particular it covers the following topics: Setting up python environment. Running simple MLCommon-Box boxes. Detailed description of the internal structure of MLCommons-Box boxes. Repository of MLCommons-Box examples. \u00b6 MLCommons hosts a simple GitHub-based repository with example MLCommons-Box boxes. It is located here . Setting-up python environment \u00b6 In various tutorials we start with setting up Python environment and downloading MLCommons-Box boxes. Here is the step by step guide: # Clone MLCommons-Box Examples git clone https://github.com/mlperf/box_examples.git && cd ./box_examples # Create Python Virtual Environment virtualenv -p python3 ./env && source ./env/bin/activate # Install MLCommons-Box Docker runner pip install mlcommons-box-docker # Optionally, setup host environment by providing the correct `http_proxy` and `https_proxy` environmental variables. # export http_proxy=... # export https_proxy=.. # Optionally, install other runners # pip install mlcommons-box-singularity # pip install mlcommons-box-ssh","title":"Introduction"},{"location":"getting-started/#getting-started","text":"This section describes some of the example MLCommon-Box boxes, in particular it covers the following topics: Setting up python environment. Running simple MLCommon-Box boxes. Detailed description of the internal structure of MLCommons-Box boxes.","title":"Getting Started"},{"location":"getting-started/#repository-of-mlcommons-box-examples","text":"MLCommons hosts a simple GitHub-based repository with example MLCommons-Box boxes. It is located here .","title":"Repository of MLCommons-Box examples."},{"location":"getting-started/#setting-up-python-environment","text":"In various tutorials we start with setting up Python environment and downloading MLCommons-Box boxes. Here is the step by step guide: # Clone MLCommons-Box Examples git clone https://github.com/mlperf/box_examples.git && cd ./box_examples # Create Python Virtual Environment virtualenv -p python3 ./env && source ./env/bin/activate # Install MLCommons-Box Docker runner pip install mlcommons-box-docker # Optionally, setup host environment by providing the correct `http_proxy` and `https_proxy` environmental variables. # export http_proxy=... # export https_proxy=.. # Optionally, install other runners # pip install mlcommons-box-singularity # pip install mlcommons-box-ssh","title":"Setting-up python environment"},{"location":"getting-started/hello-world/","text":"Hello World \u00b6 Docker runtime \u00b6 Hello World MLCommons-Box is an example of a docker-based box. Docker runtime must be installed in a system. Installation guides for various operating systems can be found here . This example was tested on a system where users are in the docker group and run docker without sudo . To add yourself to a docker group, run the following: sudo groupadd docker # Add the docker group if it doesn't already exist. sudo gpasswd -a ${USER} docker # Add the connected user \"${USER}\" to the docker group. Change the user name to match your preferred user. sudo service docker restart # Restart the Docker daemon. newgrp docker # Either do a `newgrp docker` or log out/in to activate the changes to groups. Host python environment \u00b6 Hello World is an example of a simple python program distributed as an MLCommons-Box docker-based box. Follow the steps outlined in the Introduction section to create your Python virtual environment, download example MLCommons-Box boxes and install standard MLCommons-Box runners. Go to the folder containing MLCommons-Box example boxes and change directory to Hello World Box: cd ./hello_world Configuring Hello World MLCommons-Box \u00b6 Boxes need to be configured before they can run. To do so, users need to run a MLCommons-Box runner with configure command providing path to a box root directory and path to a platform configuration file. The Hello World box is a docker-based box, so users provide path to a MLCommons-Box Docker platform configuration file that sets a number of parameters, including docker image name: mlcommons_box_docker configure --mlbox=. --platform=platforms/docker.yaml The Docker runner will build a docker image for the Hello World box. In general, this step is optional and is only required when MLCommons-Box needs to be rebuild. This can happen when users change implementation files and want to re-package their ML project into MLCommons-Box. In other situations, MLCommons-Box runners can auto-detect if configure command needs to be run before running a MLBox task. Running Hello World MLCommons-Box \u00b6 In order to run the Hello World box, users need to provide the path to the root directory of the box, platform configuration file and path to a task definition file. Run the following two commands one at a time: mlcommons_box_docker run --mlbox=. --platform=platforms/docker.yaml --task=run/alice/hello.yaml mlcommons_box_docker run --mlbox=. --platform=platforms/docker.yaml --task=run/alice/bye.yaml Hello World creates a file workspace/chats/chat_with_alice.txt that contains the following: [2020-09-03 09:13:14.236945] Hi, Alice! Nice to meet you. [2020-09-03 09:13:20.749831] Bye, Alice! It was great talking to you. Modifying MLCommons-Box \u00b6 Adding new user \u00b6 Create a new file workspace/names/donald.txt with the following content: Donald . Create a new file run/donald/hello.yaml with the following content: schema_type : mlbox_invoke schema_version : 1.0.0 task_name : hello input_binding : name : $WORKSPACE/names/donald.txt output_binding : chat : $WORKSPACE/chats/chat_with_donald.txt Create a new file run/donald/bye.yaml with the following content: schema_type : mlbox_invoke schema_version : 1.0.0 task_name : bye input_binding : name : $WORKSPACE/names/donald.txt output_binding : chat : $WORKSPACE/chats/chat_with_donald.txt Run the following two commands one at a time: mlcommons_box_docker run --mlbox=. --platform=platforms/docker.yaml --task=run/donald/hello.yaml mlcommons_box_docker run --mlbox=. --platform=platforms/docker.yaml --task=run/donald/bye.yaml The Hello World box creates a file workspace/chats/chat_with_donald.txt that contains the following: [2020-09-03 09:23:09.569558] Hi, Donald! Nice to meet you. [2020-09-03 09:23:20.076845] Bye, Donald! It was great talking to you. Providing a better greeting message \u00b6 Because how Hello World box was implemented, the greeting message is always the following: Nice to meet you. . We will update the implementation so that if this is not the first time Alice says hello , the MLBox will respond: Nice to see you again. . Modify the file build/hello_world.py . Update the function named get_greeting_message on line 14. It should have the following implementation: def get_greeting_message ( chat_file : str ) -> str : return \"Nice to meet you.\" if not os . path . exists ( chat_file ) else \"Nice to see you again.\" Since we updated a file in the build subdirectory, we need to re-configure the Hello World box: mlcommons_box_docker configure --mlbox=. --platform=platforms/docker.yaml Now, run two hello task again: mlcommons_box_docker run --mlbox=. --platform=platforms/docker.yaml --task=run/alice/hello.yaml The MLBox recognized it was not the first time it talked to Alice, and changed the greeting: [2020-09-03 09:13:14.236945] Hi, Alice! Nice to meet you. [2020-09-03 09:13:20.749831] Bye, Alice! It was great talking to you. [2020-09-03 09:32:41.369367] Hi, Alice! Nice to see you again.","title":"Hello World"},{"location":"getting-started/hello-world/#hello-world","text":"","title":"Hello World"},{"location":"getting-started/hello-world/#docker-runtime","text":"Hello World MLCommons-Box is an example of a docker-based box. Docker runtime must be installed in a system. Installation guides for various operating systems can be found here . This example was tested on a system where users are in the docker group and run docker without sudo . To add yourself to a docker group, run the following: sudo groupadd docker # Add the docker group if it doesn't already exist. sudo gpasswd -a ${USER} docker # Add the connected user \"${USER}\" to the docker group. Change the user name to match your preferred user. sudo service docker restart # Restart the Docker daemon. newgrp docker # Either do a `newgrp docker` or log out/in to activate the changes to groups.","title":"Docker runtime"},{"location":"getting-started/hello-world/#host-python-environment","text":"Hello World is an example of a simple python program distributed as an MLCommons-Box docker-based box. Follow the steps outlined in the Introduction section to create your Python virtual environment, download example MLCommons-Box boxes and install standard MLCommons-Box runners. Go to the folder containing MLCommons-Box example boxes and change directory to Hello World Box: cd ./hello_world","title":"Host python environment"},{"location":"getting-started/hello-world/#configuring-hello-world-mlcommons-box","text":"Boxes need to be configured before they can run. To do so, users need to run a MLCommons-Box runner with configure command providing path to a box root directory and path to a platform configuration file. The Hello World box is a docker-based box, so users provide path to a MLCommons-Box Docker platform configuration file that sets a number of parameters, including docker image name: mlcommons_box_docker configure --mlbox=. --platform=platforms/docker.yaml The Docker runner will build a docker image for the Hello World box. In general, this step is optional and is only required when MLCommons-Box needs to be rebuild. This can happen when users change implementation files and want to re-package their ML project into MLCommons-Box. In other situations, MLCommons-Box runners can auto-detect if configure command needs to be run before running a MLBox task.","title":"Configuring Hello World MLCommons-Box"},{"location":"getting-started/hello-world/#running-hello-world-mlcommons-box","text":"In order to run the Hello World box, users need to provide the path to the root directory of the box, platform configuration file and path to a task definition file. Run the following two commands one at a time: mlcommons_box_docker run --mlbox=. --platform=platforms/docker.yaml --task=run/alice/hello.yaml mlcommons_box_docker run --mlbox=. --platform=platforms/docker.yaml --task=run/alice/bye.yaml Hello World creates a file workspace/chats/chat_with_alice.txt that contains the following: [2020-09-03 09:13:14.236945] Hi, Alice! Nice to meet you. [2020-09-03 09:13:20.749831] Bye, Alice! It was great talking to you.","title":"Running Hello World MLCommons-Box"},{"location":"getting-started/hello-world/#modifying-mlcommons-box","text":"","title":"Modifying MLCommons-Box"},{"location":"getting-started/hello-world/#adding-new-user","text":"Create a new file workspace/names/donald.txt with the following content: Donald . Create a new file run/donald/hello.yaml with the following content: schema_type : mlbox_invoke schema_version : 1.0.0 task_name : hello input_binding : name : $WORKSPACE/names/donald.txt output_binding : chat : $WORKSPACE/chats/chat_with_donald.txt Create a new file run/donald/bye.yaml with the following content: schema_type : mlbox_invoke schema_version : 1.0.0 task_name : bye input_binding : name : $WORKSPACE/names/donald.txt output_binding : chat : $WORKSPACE/chats/chat_with_donald.txt Run the following two commands one at a time: mlcommons_box_docker run --mlbox=. --platform=platforms/docker.yaml --task=run/donald/hello.yaml mlcommons_box_docker run --mlbox=. --platform=platforms/docker.yaml --task=run/donald/bye.yaml The Hello World box creates a file workspace/chats/chat_with_donald.txt that contains the following: [2020-09-03 09:23:09.569558] Hi, Donald! Nice to meet you. [2020-09-03 09:23:20.076845] Bye, Donald! It was great talking to you.","title":"Adding new user"},{"location":"getting-started/hello-world/#providing-a-better-greeting-message","text":"Because how Hello World box was implemented, the greeting message is always the following: Nice to meet you. . We will update the implementation so that if this is not the first time Alice says hello , the MLBox will respond: Nice to see you again. . Modify the file build/hello_world.py . Update the function named get_greeting_message on line 14. It should have the following implementation: def get_greeting_message ( chat_file : str ) -> str : return \"Nice to meet you.\" if not os . path . exists ( chat_file ) else \"Nice to see you again.\" Since we updated a file in the build subdirectory, we need to re-configure the Hello World box: mlcommons_box_docker configure --mlbox=. --platform=platforms/docker.yaml Now, run two hello task again: mlcommons_box_docker run --mlbox=. --platform=platforms/docker.yaml --task=run/alice/hello.yaml The MLBox recognized it was not the first time it talked to Alice, and changed the greeting: [2020-09-03 09:13:14.236945] Hi, Alice! Nice to meet you. [2020-09-03 09:13:20.749831] Bye, Alice! It was great talking to you. [2020-09-03 09:32:41.369367] Hi, Alice! Nice to see you again.","title":"Providing a better greeting message"},{"location":"getting-started/mnist/","text":"MNIST \u00b6 The MNIST dataset is a collection of 60,000 handwritten digits widely used for training statistical, Machine Learning (ML) and Deep Learning (DL) models. The MNIST MLCommons-Box example demonstrates how data scientists, ML and DL researchers and developers can distribute their ML projects (including training, validation and inference code) as MLCommons-Box boxes. MLCommons-Box establishes a standard to package user workloads, and provides unified command line interface. In addition, MLCommons-Box provides a number of reference runners - python packages that can run boxes on different platforms including docker and singularity. A data scientist has been working on a machine learning project. The goal is to train a simple neural network to classify collection of 60,000 small images into 10 classes. MNIST training code \u00b6 Training a ML model is a process involving multiple steps such as getting data, analyzing and cleaning data, splitting into train/validation/test data sets, running hyper-parameter optimization experiments and performing final model testing. It is a relatively small and well studied dataset that provides standard train/test split. In this simple example a developer needs to implement two steps - (1) downloading data and (2) training a model. We'll call these steps as tasks . Each task requires several parameters, such as URL of the data set that we need to download, location on a local disk where the data set will be serialized, path to a directory that will contain training artifacts such as log files, training snapshots and ML models. We can characterize these two tasks in the following way: - Data Download task: - Inputs : None. We'll assume the download URL is defined in the source code. - Outputs : Directory to serialize the data set ( data_dir ) and directory to serialize log files ( log_dir ). - Training task: - Inputs : Directory with MNIST data set ( data_dir ), training hyper-parameters defined in a file ( parameters_file ). - Outputs : Directory to store training results ( model_dir ) and directory to store log files ( log_dir ). We have intentionally made all input/output parameters to be file system artifacts. By doing so, we support reproducibility. Instead of command line arguments that can easily be lost, we store them in files. There are many different ways to implement the MNIST example. For simplicity, we assume the following: - We use one python file. - Task name (download, train) is a command line positional parameter. - Both tasks write logs, so it makes sense to add parameter accepting directory for log files. - The download task accepts additional data directory parameter. - The train task accepts such parameters as data and model directories, path to a file with hyper-parameter. - Configurable hyper-parameters are: (1) optimizer name, (2) number of training epochs and (3) global batch size. Then, our implementation could look like this. Parse command line and identify task. If it is download , call a function that downloads data sets. If it is train , train a model. This is sort of single entrypoint implementation where we run one script asking to perform various tasks. We run our script (mnist.py) in the following way: python mnist.py download --data_dir=PATH --log_dir=PATH python mnist.py train --data_dir=PATH --log_dir=PATH --model_dir=PATH --parameters_file=PATH MLCommons-Box implementation \u00b6 Packaging our MNIST training script as a MLCommons-Box is done in several steps. We will be using a directory-based box where a directory is structured in a certain way and contains specific files that make it MLCommons-Box compliant. We need to create an empty directory on a local disk. Let's assume we call it mnist and we'll use {MLCOMMONS_BOX_ROOT} to denote a full path to this directory. This is called a box root directory. At this point this directory is empty: mnist/ Build location \u00b6 The box directory has a sub-directory called build ( {MLCOMMONS_BOX_ROOT}/build ) that stores project source files, resources required for training, other files to recreate run time (such as requirements.txt, docker and singularity recipes etc.). We need to create the build directory and copy two files: mnist.py that implements training and requirements.txt that lists python dependencies. By doing so, we are enforcing reproducibility. A developer of this box wants to make it easier to run their training workload in a great variety of environments including universities, commercial companies, HPC-friendly organizations such as national labs. One way to achieve it is to use container runtime such as docker or singularity. So, we'll provide both docker file and singularity recipe that we'll put into build directory as well. Thus, we'll make this directory a build context. The box directory now looks like: mnist/ build/ mnist.py requirements.txt Dockerfile Singularity.recipe A good test at this point would be ensure that project is runnable from the build directory, and docker and singularity images can be built. MLCommons-Box definition file \u00b6 At this point we are ready to create a box definition file. This is the first definition file that makes some folder a MLCommons-Box folder. This is a YAML file that provides information such as name, author, version, named as mlbox.yaml and located in the box root directory . The most important section is the one that lists what tasks are implemented in this box: schema_version : 1.0.0 # We use MLSpec library to validate YAML definition files. This is the schema_type : mlbox_root # specification of the schema that this file must be consistent with. name : mnist # Name of this box. author : MLPerf Best Practices Working Group # A developer of the box. version : 0.1.0 # MLBox version. mlbox_spec_version : 0.1.0 # TODO: What is it? tasks : # Tasks are defined in external YAML files located in tasks folder. - 'tasks/download.yaml' # \"Download data set\" task definition file. - 'tasks/train.yaml' # \"Training a model\" task definition file. At this point, the directory looks like: mnist/ build/ {mnist.py, requirements.txt, Dockerfile, Singularity.recipe} mlbox.yaml Task definition file \u00b6 The box definition file references two tasks defined in the tasks subdirectory. Each YAML file there defines a task supported by the box. Task files are named the same as tasks. We need to create a tasks directory and two files inside that directory - download.yaml and train.yaml . Each task file defines input and output specifications for each task. The download task (download.yaml) is defined: schema_version : 1.0.0 # Task schema definition. Leave this two fields as is. schema_type : mlbox_task inputs : [] # Since this task does not have any inputs, the section is empty. outputs : # This task produces two artifacts - downloaded data and log files. - name : data_dir # This parameter accepts path to a directory where data set will be serialized. type : directory # We implicitly specify that this is a directory - name : log_dir # This parameter accepts path to a directory with log files this task writes. type : directory # We implicitly specify that this is a directory Names of these parameters are the same that are accepted by mnist.py: python mnist.py download --data_dir=PATH --log_dir=PATH The train task ( train.yaml ) is defined in the following way: schema_version : 1.0.0 # Task schema definition. Leave this two fields as is. schema_type : mlbox_task inputs : # These are the task inputs. - name : data_dir # This parameter accepts path to a directory where data set will be serialized. type : directory # We implicitly specify that this is a directory - name : parameters_file # A file containing training hyper-parameters. type : file # This is a file. outputs : # These are the task outputs. - name : log_dir # This parameter accepts path to a directory with log files this task writes. type : directory # We implicitly specify that this is a directory - name : model_dir # Path to a directory where training artifacts are stored. type : directory # We implicitly specify that this is a directory Names of these parameters are the same that are accepted by mnist.py: python mnist.py train --data_dir=PATH --log_dir=PATH --model_dir=PATH --parameters_file=PATH At this point, the MLBox directory looks like: mnist/ build/ {mnist.py, requirements.txt, Dockerfile, Singularity.recipe} tasks/ {download.yaml, train.yaml} mlbox.yaml Workspace \u00b6 The workspace is a directory inside box ( workspace ) where, by default, input/output file system artifacts are stored. The are multiple reasons to have one. One is to formally have default place for data sets, configuration and log files etc. Having all these parameters in one place makes it simpler to run boxes on remote hosts and then sync results back to users' local machines. We need to be able to provide collection of hyper-parameters and formally define a directory to store logs, models and MNIST data set. To do so, we create the directory tree workspace/parameters , and then create a file ( default.parameters.yaml ) with the following content: optimizer : \"adam\" train_epochs : 5 batch_size : 32 At this point, the box directory looks like: mnist/ build/ {mnist.py, requirements.txt, Dockerfile, Singularity.recipe} tasks/ {download.yaml, train.yaml} workspace/ parameters/ default.parameters.yaml mlbox.yaml Run configurations \u00b6 The MLCommons-Box definition file ( mlbox.yaml ) provides paths to task definition files that formally define tasks input/output parameters. A run configuration assigns values to task parameters. One reason to define and \"implement\" parameters in different files is to be able to provide multiple configurations for the same task. One example could be one-GPU training configuration and 8-GPU training configuration. Since we have two tasks - download and train - we need to define at least two run configurations. Run configurations are defined in the run subdirectory. Run configuration for the download task looks like: schema_type : mlbox_invoke # Run (invoke) schema definition. Leave this two fields as is. schema_version : 1.0.0 task_name : download # Task name input_binding : {} # No input parameters for this task. output_binding : # Output parameters, format is \"parameter: value\" data_dir : $WORKSPACE/data # Path to serialize downloaded MNIST data set log_dir : $WORKSPACE/download_logs # Path to log files. The $WORKSPACE token is replaced with actual path to the box workspace. File system paths are relative to the workspace directory. This makes it possible to provide absolute paths for cases when data sets are stored on shared drives. Run configuration for the train task looks like: schema_type : mlbox_invoke # Run (invoke) schema definition. Leave this two fields as is. schema_version : 1.0.0 task_name : train # Task name input_binding : # Input parameters (name: value) data_dir : $WORKSPACE/data parameters_file : $WORKSPACE/parameters/default.parameters.yaml output_binding : # Output parameters (name: value) log_dir : $WORKSPACE/train_logs model_dir : $WORKSPACE/model At this point, the box directory looks like: mnist/ build/ {mnist.py, requirements.txt, Dockerfile, Singularity.recipe} tasks/ {download.yaml, train.yaml} workspace/parameters/default.parameters.yaml run/ download.yaml train.yaml mlbox.yaml Platform configurations \u00b6 Platform configurations define how MLCommons-Box boxes run. Docker, Singularity, SSH and cloud runners have their own configurations. For instance, Docker platform configuration at minimum provides image name and docker executable (docker / nvidia-docker). SSH platform configuration could provide IP address of a remote host, login credentials etc. Platform configurations are supposed to be used by runners, and each runner has its own platform schema. The Runners documentation section provides detailed description of reference runners together with platform configuration schemas. Since we wanted to support Docker and Singularity runtimes, we provide docker.yaml and singularity.yaml files in the platforms subdirectory that is default location to store these types of files. Docker platform configuration is the following: schema_version : 1.0.0 schema_type : mlbox_docker image : mlperf/mlbox:mnist # Docker image name docker_runtime : docker # Docker executable: docker or nvidia-docker Singularity platform configuration is the following: schema_version : 1.0.0 schema_type : mlbox_singularity image : /opt/singularity/mlperf_mlbox_mnist-0.01.simg # Path to or name of a Singularity image. At this point, the box directory looks like: mnist/ build/ {mnist.py, requirements.txt, Dockerfile, Singularity.recipe} tasks/ {download.yaml, train.yaml} workspace/parameters/default.parameters.yaml run/ {download.yaml, train.yaml} platforms/ docker.yaml singularity.yaml mlbox.yaml MNIST MLCommons-Box directory structure summary \u00b6 mnist/ # MLBox root directory. build/ # Project source code, resource files, Docker/Singularity recipes. mnist.py # Python source code training simple neural network using MNIST data set. requirements.txt # Python project dependencies. Dockerfile # Docker recipe. Singularity.recipe # Singularity recipe. tasks/ # Task definition files - define functionality that MLBox supports download.yaml # Download MNIST data set. train.yaml # Train neural network. workspace/ # Default location for data sets, logs, models, parameter files. parameters/ # Model hyper-parameters can be stored at any location. default.parameters.yaml # This is just what is used in this implementation. run/ # Run configurations - bind task parameters and values. download.yaml # Concrete run specification for the download task. train.yaml # Concrete run specification for the train task. platforms/ # Platform definition files - define how MLBox runs. docker.yaml # Docker runtime definition. singularity.yaml # Singularity runtime definition. mlbox.yaml # MLBox definition file. Running MNIST MLCommons-Box \u00b6 We need to setup the Python virtual environment. These are the steps outlined in the Introduction section except we do not clone GitHub repository with the example MLCommons-Box boxes. # Create Python Virtual Environment virtualenv -p python3 ./env && source ./env/bin/activate # Install MLCommons-Box Docker and Singularity runners pip install mlcommons-box-docker mlcommons-box-singularity # Optionally, setup host environment by providing the correct `http_proxy` and `https_proxy` environmental variables. # export http_proxy=... # export https_proxy=.. Before running MNIST box below, it is probably a good idea to remove tasks' outputs from previous runs that are located in the workspace directory. All directories except parameters can be removed. Docker Runner \u00b6 Configure MNIST box (this is optional step, docker runner checks if image exists, and if does not, runs configure phase automatically): mlcommons_box_docker configure --mlbox=. --platform=platforms/docker.yaml Run two tasks - download (download data) and train (train tiny neural network): mlcommons_box_docker run --mlbox=. --platform=platforms/docker.yaml --task=run/download.yaml mlcommons_box_docker run --mlbox=. --platform=platforms/docker.yaml --task=run/train.yaml Singularity Runner \u00b6 Update path to store Singularity image. Open platforms/singularity.yaml and update the image value that is set by default to /opt/singularity/mlperf_mlbox_mnist-0.01.simg (relative paths are supported, they are relative to workspace ). Configure MNIST box: mlcommons_box_singularity configure --mlbox=. --platform=platforms/singularity.yaml Run two tasks - download (download data) and train (train tiny neural network): mlcommons_box_singularity run --mlbox=. --platform=platforms/singularity.yaml --task=run/download.yaml mlcommons_box_singularity run --mlbox=. --platform=platforms/singularity.yaml --task=run/train.yaml","title":"MNIST"},{"location":"getting-started/mnist/#mnist","text":"The MNIST dataset is a collection of 60,000 handwritten digits widely used for training statistical, Machine Learning (ML) and Deep Learning (DL) models. The MNIST MLCommons-Box example demonstrates how data scientists, ML and DL researchers and developers can distribute their ML projects (including training, validation and inference code) as MLCommons-Box boxes. MLCommons-Box establishes a standard to package user workloads, and provides unified command line interface. In addition, MLCommons-Box provides a number of reference runners - python packages that can run boxes on different platforms including docker and singularity. A data scientist has been working on a machine learning project. The goal is to train a simple neural network to classify collection of 60,000 small images into 10 classes.","title":"MNIST"},{"location":"getting-started/mnist/#mnist-training-code","text":"Training a ML model is a process involving multiple steps such as getting data, analyzing and cleaning data, splitting into train/validation/test data sets, running hyper-parameter optimization experiments and performing final model testing. It is a relatively small and well studied dataset that provides standard train/test split. In this simple example a developer needs to implement two steps - (1) downloading data and (2) training a model. We'll call these steps as tasks . Each task requires several parameters, such as URL of the data set that we need to download, location on a local disk where the data set will be serialized, path to a directory that will contain training artifacts such as log files, training snapshots and ML models. We can characterize these two tasks in the following way: - Data Download task: - Inputs : None. We'll assume the download URL is defined in the source code. - Outputs : Directory to serialize the data set ( data_dir ) and directory to serialize log files ( log_dir ). - Training task: - Inputs : Directory with MNIST data set ( data_dir ), training hyper-parameters defined in a file ( parameters_file ). - Outputs : Directory to store training results ( model_dir ) and directory to store log files ( log_dir ). We have intentionally made all input/output parameters to be file system artifacts. By doing so, we support reproducibility. Instead of command line arguments that can easily be lost, we store them in files. There are many different ways to implement the MNIST example. For simplicity, we assume the following: - We use one python file. - Task name (download, train) is a command line positional parameter. - Both tasks write logs, so it makes sense to add parameter accepting directory for log files. - The download task accepts additional data directory parameter. - The train task accepts such parameters as data and model directories, path to a file with hyper-parameter. - Configurable hyper-parameters are: (1) optimizer name, (2) number of training epochs and (3) global batch size. Then, our implementation could look like this. Parse command line and identify task. If it is download , call a function that downloads data sets. If it is train , train a model. This is sort of single entrypoint implementation where we run one script asking to perform various tasks. We run our script (mnist.py) in the following way: python mnist.py download --data_dir=PATH --log_dir=PATH python mnist.py train --data_dir=PATH --log_dir=PATH --model_dir=PATH --parameters_file=PATH","title":"MNIST training code"},{"location":"getting-started/mnist/#mlcommons-box-implementation","text":"Packaging our MNIST training script as a MLCommons-Box is done in several steps. We will be using a directory-based box where a directory is structured in a certain way and contains specific files that make it MLCommons-Box compliant. We need to create an empty directory on a local disk. Let's assume we call it mnist and we'll use {MLCOMMONS_BOX_ROOT} to denote a full path to this directory. This is called a box root directory. At this point this directory is empty: mnist/","title":"MLCommons-Box implementation"},{"location":"getting-started/mnist/#build-location","text":"The box directory has a sub-directory called build ( {MLCOMMONS_BOX_ROOT}/build ) that stores project source files, resources required for training, other files to recreate run time (such as requirements.txt, docker and singularity recipes etc.). We need to create the build directory and copy two files: mnist.py that implements training and requirements.txt that lists python dependencies. By doing so, we are enforcing reproducibility. A developer of this box wants to make it easier to run their training workload in a great variety of environments including universities, commercial companies, HPC-friendly organizations such as national labs. One way to achieve it is to use container runtime such as docker or singularity. So, we'll provide both docker file and singularity recipe that we'll put into build directory as well. Thus, we'll make this directory a build context. The box directory now looks like: mnist/ build/ mnist.py requirements.txt Dockerfile Singularity.recipe A good test at this point would be ensure that project is runnable from the build directory, and docker and singularity images can be built.","title":"Build location"},{"location":"getting-started/mnist/#mlcommons-box-definition-file","text":"At this point we are ready to create a box definition file. This is the first definition file that makes some folder a MLCommons-Box folder. This is a YAML file that provides information such as name, author, version, named as mlbox.yaml and located in the box root directory . The most important section is the one that lists what tasks are implemented in this box: schema_version : 1.0.0 # We use MLSpec library to validate YAML definition files. This is the schema_type : mlbox_root # specification of the schema that this file must be consistent with. name : mnist # Name of this box. author : MLPerf Best Practices Working Group # A developer of the box. version : 0.1.0 # MLBox version. mlbox_spec_version : 0.1.0 # TODO: What is it? tasks : # Tasks are defined in external YAML files located in tasks folder. - 'tasks/download.yaml' # \"Download data set\" task definition file. - 'tasks/train.yaml' # \"Training a model\" task definition file. At this point, the directory looks like: mnist/ build/ {mnist.py, requirements.txt, Dockerfile, Singularity.recipe} mlbox.yaml","title":"MLCommons-Box definition file"},{"location":"getting-started/mnist/#task-definition-file","text":"The box definition file references two tasks defined in the tasks subdirectory. Each YAML file there defines a task supported by the box. Task files are named the same as tasks. We need to create a tasks directory and two files inside that directory - download.yaml and train.yaml . Each task file defines input and output specifications for each task. The download task (download.yaml) is defined: schema_version : 1.0.0 # Task schema definition. Leave this two fields as is. schema_type : mlbox_task inputs : [] # Since this task does not have any inputs, the section is empty. outputs : # This task produces two artifacts - downloaded data and log files. - name : data_dir # This parameter accepts path to a directory where data set will be serialized. type : directory # We implicitly specify that this is a directory - name : log_dir # This parameter accepts path to a directory with log files this task writes. type : directory # We implicitly specify that this is a directory Names of these parameters are the same that are accepted by mnist.py: python mnist.py download --data_dir=PATH --log_dir=PATH The train task ( train.yaml ) is defined in the following way: schema_version : 1.0.0 # Task schema definition. Leave this two fields as is. schema_type : mlbox_task inputs : # These are the task inputs. - name : data_dir # This parameter accepts path to a directory where data set will be serialized. type : directory # We implicitly specify that this is a directory - name : parameters_file # A file containing training hyper-parameters. type : file # This is a file. outputs : # These are the task outputs. - name : log_dir # This parameter accepts path to a directory with log files this task writes. type : directory # We implicitly specify that this is a directory - name : model_dir # Path to a directory where training artifacts are stored. type : directory # We implicitly specify that this is a directory Names of these parameters are the same that are accepted by mnist.py: python mnist.py train --data_dir=PATH --log_dir=PATH --model_dir=PATH --parameters_file=PATH At this point, the MLBox directory looks like: mnist/ build/ {mnist.py, requirements.txt, Dockerfile, Singularity.recipe} tasks/ {download.yaml, train.yaml} mlbox.yaml","title":"Task definition file"},{"location":"getting-started/mnist/#workspace","text":"The workspace is a directory inside box ( workspace ) where, by default, input/output file system artifacts are stored. The are multiple reasons to have one. One is to formally have default place for data sets, configuration and log files etc. Having all these parameters in one place makes it simpler to run boxes on remote hosts and then sync results back to users' local machines. We need to be able to provide collection of hyper-parameters and formally define a directory to store logs, models and MNIST data set. To do so, we create the directory tree workspace/parameters , and then create a file ( default.parameters.yaml ) with the following content: optimizer : \"adam\" train_epochs : 5 batch_size : 32 At this point, the box directory looks like: mnist/ build/ {mnist.py, requirements.txt, Dockerfile, Singularity.recipe} tasks/ {download.yaml, train.yaml} workspace/ parameters/ default.parameters.yaml mlbox.yaml","title":"Workspace"},{"location":"getting-started/mnist/#run-configurations","text":"The MLCommons-Box definition file ( mlbox.yaml ) provides paths to task definition files that formally define tasks input/output parameters. A run configuration assigns values to task parameters. One reason to define and \"implement\" parameters in different files is to be able to provide multiple configurations for the same task. One example could be one-GPU training configuration and 8-GPU training configuration. Since we have two tasks - download and train - we need to define at least two run configurations. Run configurations are defined in the run subdirectory. Run configuration for the download task looks like: schema_type : mlbox_invoke # Run (invoke) schema definition. Leave this two fields as is. schema_version : 1.0.0 task_name : download # Task name input_binding : {} # No input parameters for this task. output_binding : # Output parameters, format is \"parameter: value\" data_dir : $WORKSPACE/data # Path to serialize downloaded MNIST data set log_dir : $WORKSPACE/download_logs # Path to log files. The $WORKSPACE token is replaced with actual path to the box workspace. File system paths are relative to the workspace directory. This makes it possible to provide absolute paths for cases when data sets are stored on shared drives. Run configuration for the train task looks like: schema_type : mlbox_invoke # Run (invoke) schema definition. Leave this two fields as is. schema_version : 1.0.0 task_name : train # Task name input_binding : # Input parameters (name: value) data_dir : $WORKSPACE/data parameters_file : $WORKSPACE/parameters/default.parameters.yaml output_binding : # Output parameters (name: value) log_dir : $WORKSPACE/train_logs model_dir : $WORKSPACE/model At this point, the box directory looks like: mnist/ build/ {mnist.py, requirements.txt, Dockerfile, Singularity.recipe} tasks/ {download.yaml, train.yaml} workspace/parameters/default.parameters.yaml run/ download.yaml train.yaml mlbox.yaml","title":"Run configurations"},{"location":"getting-started/mnist/#platform-configurations","text":"Platform configurations define how MLCommons-Box boxes run. Docker, Singularity, SSH and cloud runners have their own configurations. For instance, Docker platform configuration at minimum provides image name and docker executable (docker / nvidia-docker). SSH platform configuration could provide IP address of a remote host, login credentials etc. Platform configurations are supposed to be used by runners, and each runner has its own platform schema. The Runners documentation section provides detailed description of reference runners together with platform configuration schemas. Since we wanted to support Docker and Singularity runtimes, we provide docker.yaml and singularity.yaml files in the platforms subdirectory that is default location to store these types of files. Docker platform configuration is the following: schema_version : 1.0.0 schema_type : mlbox_docker image : mlperf/mlbox:mnist # Docker image name docker_runtime : docker # Docker executable: docker or nvidia-docker Singularity platform configuration is the following: schema_version : 1.0.0 schema_type : mlbox_singularity image : /opt/singularity/mlperf_mlbox_mnist-0.01.simg # Path to or name of a Singularity image. At this point, the box directory looks like: mnist/ build/ {mnist.py, requirements.txt, Dockerfile, Singularity.recipe} tasks/ {download.yaml, train.yaml} workspace/parameters/default.parameters.yaml run/ {download.yaml, train.yaml} platforms/ docker.yaml singularity.yaml mlbox.yaml","title":"Platform configurations"},{"location":"getting-started/mnist/#mnist-mlcommons-box-directory-structure-summary","text":"mnist/ # MLBox root directory. build/ # Project source code, resource files, Docker/Singularity recipes. mnist.py # Python source code training simple neural network using MNIST data set. requirements.txt # Python project dependencies. Dockerfile # Docker recipe. Singularity.recipe # Singularity recipe. tasks/ # Task definition files - define functionality that MLBox supports download.yaml # Download MNIST data set. train.yaml # Train neural network. workspace/ # Default location for data sets, logs, models, parameter files. parameters/ # Model hyper-parameters can be stored at any location. default.parameters.yaml # This is just what is used in this implementation. run/ # Run configurations - bind task parameters and values. download.yaml # Concrete run specification for the download task. train.yaml # Concrete run specification for the train task. platforms/ # Platform definition files - define how MLBox runs. docker.yaml # Docker runtime definition. singularity.yaml # Singularity runtime definition. mlbox.yaml # MLBox definition file.","title":"MNIST MLCommons-Box directory structure summary"},{"location":"getting-started/mnist/#running-mnist-mlcommons-box","text":"We need to setup the Python virtual environment. These are the steps outlined in the Introduction section except we do not clone GitHub repository with the example MLCommons-Box boxes. # Create Python Virtual Environment virtualenv -p python3 ./env && source ./env/bin/activate # Install MLCommons-Box Docker and Singularity runners pip install mlcommons-box-docker mlcommons-box-singularity # Optionally, setup host environment by providing the correct `http_proxy` and `https_proxy` environmental variables. # export http_proxy=... # export https_proxy=.. Before running MNIST box below, it is probably a good idea to remove tasks' outputs from previous runs that are located in the workspace directory. All directories except parameters can be removed.","title":"Running MNIST MLCommons-Box"},{"location":"getting-started/mnist/#docker-runner","text":"Configure MNIST box (this is optional step, docker runner checks if image exists, and if does not, runs configure phase automatically): mlcommons_box_docker configure --mlbox=. --platform=platforms/docker.yaml Run two tasks - download (download data) and train (train tiny neural network): mlcommons_box_docker run --mlbox=. --platform=platforms/docker.yaml --task=run/download.yaml mlcommons_box_docker run --mlbox=. --platform=platforms/docker.yaml --task=run/train.yaml","title":"Docker Runner"},{"location":"getting-started/mnist/#singularity-runner","text":"Update path to store Singularity image. Open platforms/singularity.yaml and update the image value that is set by default to /opt/singularity/mlperf_mlbox_mnist-0.01.simg (relative paths are supported, they are relative to workspace ). Configure MNIST box: mlcommons_box_singularity configure --mlbox=. --platform=platforms/singularity.yaml Run two tasks - download (download data) and train (train tiny neural network): mlcommons_box_singularity run --mlbox=. --platform=platforms/singularity.yaml --task=run/download.yaml mlcommons_box_singularity run --mlbox=. --platform=platforms/singularity.yaml --task=run/train.yaml","title":"Singularity Runner"},{"location":"runners/","text":"Runners \u00b6 A runner is a tool that runs MLCommons-Box boxes on one or multiple platforms. Examples of platforms are docker and singularity containers, remote hosts, virtual machines in the cloud, etc. A platform is configured in a platform configuration file. A box can provide reference platform configurations that users can modify to meet requirements of their infrastructures. MLCommons-Box standard requires that all runners implement mandatory functionality. All reference runners implement it. Users can develop their own runners to meet their specific requirements, such as security, authentication and authorization policies and others. Reference MLCommons-Box runners \u00b6 Reference runners are: - Docker Runner : Runs boxes using docker runtime. - Singularity Runner : Runs boxes using singularity runtime. - SSH Runner : Runs boxes on remote hosts. SSH Runner uses other runners, such as Docker or Singularity runners, to run boxes on remote hosts. Runner commands \u00b6 Each runner exposes mandatory and optional functionality through a set of commands. This is similar to, for instance, how Git implements its CLI ( git followed by a specific command such as checkout , pull , push etc). Mandatory MLCommons-Box runner commands are configure and run : - configure : Configure MLCommons-Box. Exact functionality depends on a runner type, but the goal is to ensure that a box is ready to run. The following are the examples of what can be done at configure phase: build docker or singularity container, create python virtual environment, allocate and configure virtual machine in the cloud, copy box to a remote host etc. Once configuration is successfully completed, it is assumed a runner can run that box. - run : Run tasks defined in MLCommons-Box. Reference runners recognize three parameters - mlbox, platform and task. - mlbox : Path to a box root directory. In future versions, this can be an URI with a specific protocol. Runners could support various MLCommons-Box implementations (excluding reference directory-based) such as docker/singularity containers, GitHub repositories, compressed archives and others. - platform : Path to a YAML-based platform configuration file. If not present, a runner should use the default platforms to run a box, or select the most appropriate or available in a user environment. - task : Path to a YAML-based task specification file. If not present, a runner can run the default task. Command line interface \u00b6 One way to run a MLCommons-Box is to follow the following template supported by all reference runners: python -m RUNNER_PACKAGE --mlbox=MLCOMMONS_BOX_ROOT_DIRECTORY --platform=PLATFORM_FILE_PATH --task=TASK_FILE_PATH Example command to configure MNIST Docker-based MLCommons-Box: python -m mlbox_docker configure --mlbox=examples/mnist --platform=examples/mnist/platform/docker.yaml Example command to run two tasks implemented by the MNIST Docker-based MLCommons-Box: python -m mlbox_docker run --mlbox=examples/mnist --platform=examples/mnist/platform/docker.yaml --task=examples/mnist/run/download.yaml python -m mlbox_docker run --mlbox=examples/mnist --platform=examples/mnist/platform/docker.yaml --task=examples/mnist/run/train.yaml","title":"Runners"},{"location":"runners/#runners","text":"A runner is a tool that runs MLCommons-Box boxes on one or multiple platforms. Examples of platforms are docker and singularity containers, remote hosts, virtual machines in the cloud, etc. A platform is configured in a platform configuration file. A box can provide reference platform configurations that users can modify to meet requirements of their infrastructures. MLCommons-Box standard requires that all runners implement mandatory functionality. All reference runners implement it. Users can develop their own runners to meet their specific requirements, such as security, authentication and authorization policies and others.","title":"Runners"},{"location":"runners/#reference-mlcommons-box-runners","text":"Reference runners are: - Docker Runner : Runs boxes using docker runtime. - Singularity Runner : Runs boxes using singularity runtime. - SSH Runner : Runs boxes on remote hosts. SSH Runner uses other runners, such as Docker or Singularity runners, to run boxes on remote hosts.","title":"Reference MLCommons-Box runners"},{"location":"runners/#runner-commands","text":"Each runner exposes mandatory and optional functionality through a set of commands. This is similar to, for instance, how Git implements its CLI ( git followed by a specific command such as checkout , pull , push etc). Mandatory MLCommons-Box runner commands are configure and run : - configure : Configure MLCommons-Box. Exact functionality depends on a runner type, but the goal is to ensure that a box is ready to run. The following are the examples of what can be done at configure phase: build docker or singularity container, create python virtual environment, allocate and configure virtual machine in the cloud, copy box to a remote host etc. Once configuration is successfully completed, it is assumed a runner can run that box. - run : Run tasks defined in MLCommons-Box. Reference runners recognize three parameters - mlbox, platform and task. - mlbox : Path to a box root directory. In future versions, this can be an URI with a specific protocol. Runners could support various MLCommons-Box implementations (excluding reference directory-based) such as docker/singularity containers, GitHub repositories, compressed archives and others. - platform : Path to a YAML-based platform configuration file. If not present, a runner should use the default platforms to run a box, or select the most appropriate or available in a user environment. - task : Path to a YAML-based task specification file. If not present, a runner can run the default task.","title":"Runner commands"},{"location":"runners/#command-line-interface","text":"One way to run a MLCommons-Box is to follow the following template supported by all reference runners: python -m RUNNER_PACKAGE --mlbox=MLCOMMONS_BOX_ROOT_DIRECTORY --platform=PLATFORM_FILE_PATH --task=TASK_FILE_PATH Example command to configure MNIST Docker-based MLCommons-Box: python -m mlbox_docker configure --mlbox=examples/mnist --platform=examples/mnist/platform/docker.yaml Example command to run two tasks implemented by the MNIST Docker-based MLCommons-Box: python -m mlbox_docker run --mlbox=examples/mnist --platform=examples/mnist/platform/docker.yaml --task=examples/mnist/run/download.yaml python -m mlbox_docker run --mlbox=examples/mnist --platform=examples/mnist/platform/docker.yaml --task=examples/mnist/run/train.yaml","title":"Command line interface"},{"location":"runners/docker-runner/","text":"Docker Runner \u00b6 Docker runner uses docker/nvidia-docker to run MLCommons-Box boxes. It supports two mandatory commands - configure and run with standard arguments - mlbox , platform and task . Docker platform configuration is used to configure docker runner. Platform Configuration File \u00b6 Docker platform configuration file is a YAML file that follows mlbox_docker ML schema. The configuration file for the reference MNIST box is the following: schema_version : 1.0.0 schema_type : mlbox_docker image : mlperf/mlbox:mnist # Docker image name docker_runtime : docker # Docker executable: docker or nvidia-docker Additional configuration \u00b6 In current implementation, Docker runner uses http_proxy and https_proxy environmental variables (if set) during configure and run phases: - configure : docker build ... --build-args http_proxy=${http_proxy} --build-args https_proxy=${https_proxy} ... - run : docker run ... -e http_proxy=${http_proxy} -e https_proxy=${https_proxy} ... Configuring MLBoxes \u00b6 Docker runner uses {MLCOMMONS_BOX_ROOT}/build directory as the build context directory. This implies that all files that must be packaged in a docker image, must be located in that directory, including source files, python requirements, resource files, ML models etc. The docker recipe must have the standard name Dockerfile . If Dockerfile file exists in {MLCOMMONS_BOX_ROOT}/build , the Docker runner assumes that it needs to build a docker image. If that file does not exists, the Docker runner will try to pull image with the specified name. Docker runner under the hood runs the following command line: cd {build_path}; docker build {env_args} -t {image_name} -f Dockerfile . where: - {build_path} is {MLCOMMONS_BOX_ROOT}/build root directory. - {env_args} is the arguments retrieved from user environment. Currently, only http_proxy and https_proxy are supported. - {image_name} is the image name defined in the platform configuration file. The configure command is optional and users do not necessarily need to be aware about it. The Docker runner auto-detects if docker image exists before running a task, and if it does not exist, the docker runner runs the configure command. During the configure phase, docker runner does not check if docker image exists. This means the following. If some of the implementation files have been modified, to rebuild the docker image users need to run the configure command explicitly. Running MLBoxes \u00b6 Docker runner runs the following command: {docker_runtime} run --rm --net=host --privileged=true {volumes} {env_args} {image_name} {args} where: - {docker_exec} is the docker_runtime value from the Docker platform configuration file. - {volumes} are the mount points that the runner automatically constructs based upon the task input/output specifications. - {env_args} is the arguments retrieved from user environment, currently, only http_proxy and https_proxy are supported. - {image_name} is the image name from the platform configuration file. - {args} is the task command line arguments, constructed automatically by the runner.","title":"Docker Runner"},{"location":"runners/docker-runner/#docker-runner","text":"Docker runner uses docker/nvidia-docker to run MLCommons-Box boxes. It supports two mandatory commands - configure and run with standard arguments - mlbox , platform and task . Docker platform configuration is used to configure docker runner.","title":"Docker Runner"},{"location":"runners/docker-runner/#platform-configuration-file","text":"Docker platform configuration file is a YAML file that follows mlbox_docker ML schema. The configuration file for the reference MNIST box is the following: schema_version : 1.0.0 schema_type : mlbox_docker image : mlperf/mlbox:mnist # Docker image name docker_runtime : docker # Docker executable: docker or nvidia-docker","title":"Platform Configuration File"},{"location":"runners/docker-runner/#additional-configuration","text":"In current implementation, Docker runner uses http_proxy and https_proxy environmental variables (if set) during configure and run phases: - configure : docker build ... --build-args http_proxy=${http_proxy} --build-args https_proxy=${https_proxy} ... - run : docker run ... -e http_proxy=${http_proxy} -e https_proxy=${https_proxy} ...","title":"Additional configuration"},{"location":"runners/docker-runner/#configuring-mlboxes","text":"Docker runner uses {MLCOMMONS_BOX_ROOT}/build directory as the build context directory. This implies that all files that must be packaged in a docker image, must be located in that directory, including source files, python requirements, resource files, ML models etc. The docker recipe must have the standard name Dockerfile . If Dockerfile file exists in {MLCOMMONS_BOX_ROOT}/build , the Docker runner assumes that it needs to build a docker image. If that file does not exists, the Docker runner will try to pull image with the specified name. Docker runner under the hood runs the following command line: cd {build_path}; docker build {env_args} -t {image_name} -f Dockerfile . where: - {build_path} is {MLCOMMONS_BOX_ROOT}/build root directory. - {env_args} is the arguments retrieved from user environment. Currently, only http_proxy and https_proxy are supported. - {image_name} is the image name defined in the platform configuration file. The configure command is optional and users do not necessarily need to be aware about it. The Docker runner auto-detects if docker image exists before running a task, and if it does not exist, the docker runner runs the configure command. During the configure phase, docker runner does not check if docker image exists. This means the following. If some of the implementation files have been modified, to rebuild the docker image users need to run the configure command explicitly.","title":"Configuring MLBoxes"},{"location":"runners/docker-runner/#running-mlboxes","text":"Docker runner runs the following command: {docker_runtime} run --rm --net=host --privileged=true {volumes} {env_args} {image_name} {args} where: - {docker_exec} is the docker_runtime value from the Docker platform configuration file. - {volumes} are the mount points that the runner automatically constructs based upon the task input/output specifications. - {env_args} is the arguments retrieved from user environment, currently, only http_proxy and https_proxy are supported. - {image_name} is the image name from the platform configuration file. - {args} is the task command line arguments, constructed automatically by the runner.","title":"Running MLBoxes"},{"location":"runners/kubernetes/","text":"Kubernetes Runner \u00b6 The Kubernetes Runner runs a MLCommons-Box on a Kubernetes cluster. Skip over to the fun part. Why Kubernetes? \u00b6 One of the key goals of the MLCommons-Box project is to enable portability of ML models. Kubernetes offers the a good set of abstractions to enable model training to be portable across different compute platforms. Design \u00b6 Kubernetes Runner Proposal Doc The Kubernetes runner takes in a kubernetes specific task file in the run directory and re-uses the Docker runner platform config and prepares a Kubernetes Job manifest. The runner then creates the job on the Kubernetes cluster. The Kubernetes Runner takes in a MLBox run configuration file similar to other runners. With clear definitions of input and output bindings. Here's an example: schema_type : mlbox_invoke schema_version : 1.0.0 task_name : kubernetes # task name set to 'kubernetes' input_binding : # input parameters (name: value) data_dir : path : workspace/data k8s : pvc : mlbox-input ... output_binding : # output parameters (name: value) model_dir : path : workspace/model k8s : pvc : mlbox-output ... The Runner also re-uses the Docker platform config file. So it needs a Docker platform config file in the Box. Let's revisit the Docker platform config. schema_type : mlcommons_box_platform schema_version : 0.1.0 platform : name : \"docker\" version : \">=18.01\" container : image : \"mlperf/mlbox:mnist\" With these two config files, the runner then constructs the following Kubernetes Job manifest. apiVersion : batch/v1 kind : Job metadata : namespace : default generateName : mlcommons-box-mnist- spec : template : spec : containers : - name : mlcommons-box-container image : mlperf/mlbox:mnist args : - --data_dir=/mnt/mlbox/mlbox-input/workspace/data - --model_dir=/mnt/mlbox/mlbox-output/workspace/model volumeMounts : - name : mlbox-input mountPath : /mnt/mlbox/mlbox-input - name : mlbox-output mountPath : /mnt/mlbox/mlbox-output volumes : - name : mlbox-input persistentVolumeClaim : claimName : mlbox-input - name : mlbox-output persistentVolumeClaim : claimName : mlbox-output restartPolicy : Never backoffLimit : 4 Configure a Box for the runner \u00b6 Prerequisites: A Kubernetes cluster KUBECONFIG for the cluster pre-created volumes for the Box Create a Task file \u00b6 Based on the setup, create a specific task file for the Box. Create a YAML file in the run directory \u00b6 touch run/kubernetes.yaml Set Schema for Task \u00b6 schema_type : mlbox_invoke schema_version : 1.0.0 Set task name \u00b6 task_name : kubernetes Set input and output bindings \u00b6 input_binding : # input parameters (name: value) data_dir : path : workspace/data k8s : pvc : mlbox-input output_binding : # output parameters (name: value) model_dir : path : workspace/model k8s : pvc : mlbox-output Run a box with the CLI \u00b6 pip install mlcommons-box-k8s mlcommons_box_k8s run \\ --mlbox = examples/mnist \\ --platform = examples/mnist/platforms/docker.yaml \\ --task = examples/mnist/run/kubernetes.yaml \\ --loglevel INFO","title":"Kubernetes Runner"},{"location":"runners/kubernetes/#kubernetes-runner","text":"The Kubernetes Runner runs a MLCommons-Box on a Kubernetes cluster. Skip over to the fun part.","title":"Kubernetes Runner"},{"location":"runners/kubernetes/#why-kubernetes","text":"One of the key goals of the MLCommons-Box project is to enable portability of ML models. Kubernetes offers the a good set of abstractions to enable model training to be portable across different compute platforms.","title":"Why Kubernetes?"},{"location":"runners/kubernetes/#design","text":"Kubernetes Runner Proposal Doc The Kubernetes runner takes in a kubernetes specific task file in the run directory and re-uses the Docker runner platform config and prepares a Kubernetes Job manifest. The runner then creates the job on the Kubernetes cluster. The Kubernetes Runner takes in a MLBox run configuration file similar to other runners. With clear definitions of input and output bindings. Here's an example: schema_type : mlbox_invoke schema_version : 1.0.0 task_name : kubernetes # task name set to 'kubernetes' input_binding : # input parameters (name: value) data_dir : path : workspace/data k8s : pvc : mlbox-input ... output_binding : # output parameters (name: value) model_dir : path : workspace/model k8s : pvc : mlbox-output ... The Runner also re-uses the Docker platform config file. So it needs a Docker platform config file in the Box. Let's revisit the Docker platform config. schema_type : mlcommons_box_platform schema_version : 0.1.0 platform : name : \"docker\" version : \">=18.01\" container : image : \"mlperf/mlbox:mnist\" With these two config files, the runner then constructs the following Kubernetes Job manifest. apiVersion : batch/v1 kind : Job metadata : namespace : default generateName : mlcommons-box-mnist- spec : template : spec : containers : - name : mlcommons-box-container image : mlperf/mlbox:mnist args : - --data_dir=/mnt/mlbox/mlbox-input/workspace/data - --model_dir=/mnt/mlbox/mlbox-output/workspace/model volumeMounts : - name : mlbox-input mountPath : /mnt/mlbox/mlbox-input - name : mlbox-output mountPath : /mnt/mlbox/mlbox-output volumes : - name : mlbox-input persistentVolumeClaim : claimName : mlbox-input - name : mlbox-output persistentVolumeClaim : claimName : mlbox-output restartPolicy : Never backoffLimit : 4","title":"Design"},{"location":"runners/kubernetes/#configure-a-box-for-the-runner","text":"Prerequisites: A Kubernetes cluster KUBECONFIG for the cluster pre-created volumes for the Box","title":"Configure a Box for the runner"},{"location":"runners/kubernetes/#create-a-task-file","text":"Based on the setup, create a specific task file for the Box.","title":"Create a Task file"},{"location":"runners/kubernetes/#create-a-yaml-file-in-the-run-directory","text":"touch run/kubernetes.yaml","title":"Create a YAML file in the run directory"},{"location":"runners/kubernetes/#set-schema-for-task","text":"schema_type : mlbox_invoke schema_version : 1.0.0","title":"Set Schema for Task"},{"location":"runners/kubernetes/#set-task-name","text":"task_name : kubernetes","title":"Set task name"},{"location":"runners/kubernetes/#set-input-and-output-bindings","text":"input_binding : # input parameters (name: value) data_dir : path : workspace/data k8s : pvc : mlbox-input output_binding : # output parameters (name: value) model_dir : path : workspace/model k8s : pvc : mlbox-output","title":"Set input and output bindings"},{"location":"runners/kubernetes/#run-a-box-with-the-cli","text":"pip install mlcommons-box-k8s mlcommons_box_k8s run \\ --mlbox = examples/mnist \\ --platform = examples/mnist/platforms/docker.yaml \\ --task = examples/mnist/run/kubernetes.yaml \\ --loglevel INFO","title":"Run a box with the CLI"},{"location":"runners/singularity-runner/","text":"Singularity Runner \u00b6 Singularity runner uses singularity to run MLCommon-Box boxes. It supports two mandatory commands - configure and run with standard arguments - mlbox , platform and task . Singularity platform configuration is used to configure Singularity runner. Platform Configuration File \u00b6 Singularity platform configuration file is a YAML file that follows mlbox_singularity ML schema. The configuration file for the reference MNIST box is the following: schema_version : 1.0.0 schema_type : mlbox_singularity image : /opt/singularity/mlperf_mlbox_mnist-0.01.simg # Path to or name of a Singularity image. The image field above is a path to a singularity container. It is relative to {MLCOMMONS_BOX_ROOT}/workspace : - By default, containers are stored in {MLCOMMONS_BOX_ROOT}/workspace if image is a file name. - If it is a relative path, it is relative to {MLCOMMONS_BOX_ROOT}/workspace . - Absolute paths (starting with /) are used as is. In the example above, Singularity image is stored in the directory outside of the {MLCOMMONS_BOX_ROOT} to avoid copying it back to a user host when using runners such as SSH. Build command \u00b6 Singularity runner uses {MLCOMMONS_BOX_ROOT}/build directory as the build context directory. This implies that all files that must be packaged in a singularity image, must be located in that directory, including source files, python requirements, resource files, ML models etc. The singularity recipe must have the standard name Singularity.recipe . Singularity runner under the hood runs the following command line: cd {build_path}; singularity build --fakeroot {image_path} Singularity.recipe where: - {build_path} is {MLCOMMONS_BOX_ROOT}/build root directory. - {image_path} is the path to Singularity image that is computed as described above. Run command \u00b6 Singularity runner runs the following command: singularity run {volumes} {image_path} {args} where: - {volumes} are the mount points that the runner automatically constructs based upon the task input/output specifications. - {image_path} is the path to Singularity image that is computed as described above. - {args} is the task command line arguments, constructed automatically by the runner.","title":"Singularity Runner"},{"location":"runners/singularity-runner/#singularity-runner","text":"Singularity runner uses singularity to run MLCommon-Box boxes. It supports two mandatory commands - configure and run with standard arguments - mlbox , platform and task . Singularity platform configuration is used to configure Singularity runner.","title":"Singularity Runner"},{"location":"runners/singularity-runner/#platform-configuration-file","text":"Singularity platform configuration file is a YAML file that follows mlbox_singularity ML schema. The configuration file for the reference MNIST box is the following: schema_version : 1.0.0 schema_type : mlbox_singularity image : /opt/singularity/mlperf_mlbox_mnist-0.01.simg # Path to or name of a Singularity image. The image field above is a path to a singularity container. It is relative to {MLCOMMONS_BOX_ROOT}/workspace : - By default, containers are stored in {MLCOMMONS_BOX_ROOT}/workspace if image is a file name. - If it is a relative path, it is relative to {MLCOMMONS_BOX_ROOT}/workspace . - Absolute paths (starting with /) are used as is. In the example above, Singularity image is stored in the directory outside of the {MLCOMMONS_BOX_ROOT} to avoid copying it back to a user host when using runners such as SSH.","title":"Platform Configuration File"},{"location":"runners/singularity-runner/#build-command","text":"Singularity runner uses {MLCOMMONS_BOX_ROOT}/build directory as the build context directory. This implies that all files that must be packaged in a singularity image, must be located in that directory, including source files, python requirements, resource files, ML models etc. The singularity recipe must have the standard name Singularity.recipe . Singularity runner under the hood runs the following command line: cd {build_path}; singularity build --fakeroot {image_path} Singularity.recipe where: - {build_path} is {MLCOMMONS_BOX_ROOT}/build root directory. - {image_path} is the path to Singularity image that is computed as described above.","title":"Build command"},{"location":"runners/singularity-runner/#run-command","text":"Singularity runner runs the following command: singularity run {volumes} {image_path} {args} where: - {volumes} are the mount points that the runner automatically constructs based upon the task input/output specifications. - {image_path} is the path to Singularity image that is computed as described above. - {args} is the task command line arguments, constructed automatically by the runner.","title":"Run command"},{"location":"runners/ssh-runner/","text":"SSH Runner \u00b6 SSH runner uses other runners to run MLCommons-Box boxes on remote hosts. It uses ssh and rsync internally. It supports two mandatory commands - configure and run with standard arguments - mlbox , platform and task . SSH platform configuration is used to configure SSH runner. This runner is being actively developed and not all features described on this page may be supported. Platform Configuration File \u00b6 SSH platform configuration file is a YAML file. The configuration file for the reference MNIST box is the following: # Possible values are hostname or IP address. It can also be a host alias if there is a corresponding section # exists in ~/.ssh/config. The hostname should be possible to use with tools like ssh, rsync and scp. host : REMOTE_HOST # Authentication section is optional, and can be null, empty or non-empty dictionary. If value is null or empty # string/dict, it is assumed the authentication is not required, or is configured in user environment # (e.g. ~/.ssh/config). SSH runner will not provide any additional information on a command line for ssh, rsync or scp. # If the value is a dictionary, optional fields that SSH runner recognizes are user name on a remote host (user) and # path to a user private key file (identity_file). If all fields are present, the following connection string is used # by the SSH runner: `-i $identity_file $user@$host`. authentication : user : USER identity_file : /opt/mlbox/ssh/gcp_identity # The platform field points to a platform configuration to be used on a remote host. This file must be located inside # $mlbox_root/platforms directory. The idea is that the SSH runner delivers an MLBox to a remote host and then use # another MLCommons-Box runner such as Docker or Singularity runner to run that MLBox there. platform : docker.yaml # The interpreter section defines python interpreter on a remote host to use to run other runners there. This is not # environment for MLBoxes, this is environment for runners to run MLBoxes. Two options are supported - `system` and # `virtualenv` interpreters. # The system interpreter is a python already available on a remote host. It can be just an executable (python, # python3.8) or a full path to a user existing environment. Three fields should be provided: type (system in this case), # python executable, possibly, with fully specified path, and dependencies in the form of a string (requirements). interpreter : type : \"system\" python : \"python3.6\" requirements : \"mlcommons-box-docker==0.2.2\" # The virtualenv interpreter does not have to exist. SSH runner can create this one. This interpreter has the same # fields with two additional ones - location (base path for a python environment) and name (basically, a folder name # inside the location path). # interpreter: # type: \"virtualenv\" # python: \"python3.6\" # requirements: \"mlcommons-box-docker==0.2.1\" # location: \"${HOME}/mlcommons-box/environments\" # name: \"mlcommons-box-docker-0.2.1\" SSH runner uses IP or name of a remote host ( host ) and ssh tool to login and execute shell commands on remote hosts. If passwordless login is not configured, SSH runner asks for password many times during configure and run phases. SSH runner depends on other runners to run MLCommons-Box boxes. The platform field specifies what runner should be used on a remote host. This is a file name located in {MLCOMMONS_BOX_ROOT}/platforms . In current implementation, SSH runner synchronizes only an mlbox workload between local and remote hosts. Runners are assumed to be either available on remote hosts or specified as package dependencies in python interpreter configuration section. Configure command \u00b6 During the build phase, the following steps are performed. 1. Based upon configuration, SSH runner creates and/or configures python on a remote host using ssh . This includes execution of such commands as virtualenv -p ... and/or source ... && pip install ... on a remote host. Default path for a python environment on a remote host is ${HOME}/mlcommons-box/environments/ . 2. SSH runner copies mlbox directory to a remote host. Default path on a remote host is ${HOME}/mlcommons-box/boxes/ . 3. SSH runner runs another runner specified in a platform configuration file on a remote host to configure it. Run command \u00b6 During the run phase, the SSH runner performs the following steps: 1. It uses ssh to run standard run command on a remote host. 2. It uses rsync to synchronize back the content of the {MLCOMMONS_BOX_ROOT}/workspace directory.","title":"SSH Runner"},{"location":"runners/ssh-runner/#ssh-runner","text":"SSH runner uses other runners to run MLCommons-Box boxes on remote hosts. It uses ssh and rsync internally. It supports two mandatory commands - configure and run with standard arguments - mlbox , platform and task . SSH platform configuration is used to configure SSH runner. This runner is being actively developed and not all features described on this page may be supported.","title":"SSH Runner"},{"location":"runners/ssh-runner/#platform-configuration-file","text":"SSH platform configuration file is a YAML file. The configuration file for the reference MNIST box is the following: # Possible values are hostname or IP address. It can also be a host alias if there is a corresponding section # exists in ~/.ssh/config. The hostname should be possible to use with tools like ssh, rsync and scp. host : REMOTE_HOST # Authentication section is optional, and can be null, empty or non-empty dictionary. If value is null or empty # string/dict, it is assumed the authentication is not required, or is configured in user environment # (e.g. ~/.ssh/config). SSH runner will not provide any additional information on a command line for ssh, rsync or scp. # If the value is a dictionary, optional fields that SSH runner recognizes are user name on a remote host (user) and # path to a user private key file (identity_file). If all fields are present, the following connection string is used # by the SSH runner: `-i $identity_file $user@$host`. authentication : user : USER identity_file : /opt/mlbox/ssh/gcp_identity # The platform field points to a platform configuration to be used on a remote host. This file must be located inside # $mlbox_root/platforms directory. The idea is that the SSH runner delivers an MLBox to a remote host and then use # another MLCommons-Box runner such as Docker or Singularity runner to run that MLBox there. platform : docker.yaml # The interpreter section defines python interpreter on a remote host to use to run other runners there. This is not # environment for MLBoxes, this is environment for runners to run MLBoxes. Two options are supported - `system` and # `virtualenv` interpreters. # The system interpreter is a python already available on a remote host. It can be just an executable (python, # python3.8) or a full path to a user existing environment. Three fields should be provided: type (system in this case), # python executable, possibly, with fully specified path, and dependencies in the form of a string (requirements). interpreter : type : \"system\" python : \"python3.6\" requirements : \"mlcommons-box-docker==0.2.2\" # The virtualenv interpreter does not have to exist. SSH runner can create this one. This interpreter has the same # fields with two additional ones - location (base path for a python environment) and name (basically, a folder name # inside the location path). # interpreter: # type: \"virtualenv\" # python: \"python3.6\" # requirements: \"mlcommons-box-docker==0.2.1\" # location: \"${HOME}/mlcommons-box/environments\" # name: \"mlcommons-box-docker-0.2.1\" SSH runner uses IP or name of a remote host ( host ) and ssh tool to login and execute shell commands on remote hosts. If passwordless login is not configured, SSH runner asks for password many times during configure and run phases. SSH runner depends on other runners to run MLCommons-Box boxes. The platform field specifies what runner should be used on a remote host. This is a file name located in {MLCOMMONS_BOX_ROOT}/platforms . In current implementation, SSH runner synchronizes only an mlbox workload between local and remote hosts. Runners are assumed to be either available on remote hosts or specified as package dependencies in python interpreter configuration section.","title":"Platform Configuration File"},{"location":"runners/ssh-runner/#configure-command","text":"During the build phase, the following steps are performed. 1. Based upon configuration, SSH runner creates and/or configures python on a remote host using ssh . This includes execution of such commands as virtualenv -p ... and/or source ... && pip install ... on a remote host. Default path for a python environment on a remote host is ${HOME}/mlcommons-box/environments/ . 2. SSH runner copies mlbox directory to a remote host. Default path on a remote host is ${HOME}/mlcommons-box/boxes/ . 3. SSH runner runs another runner specified in a platform configuration file on a remote host to configure it.","title":"Configure command"},{"location":"runners/ssh-runner/#run-command","text":"During the run phase, the SSH runner performs the following steps: 1. It uses ssh to run standard run command on a remote host. 2. It uses rsync to synchronize back the content of the {MLCOMMONS_BOX_ROOT}/workspace directory.","title":"Run command"}]}