{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"MLBox \u00b6 This is the MLBox \ud83d\udce6 Prototype. Get MLBox \u00b6 Direct Download \u00b6 Directly download the project wget -O mlbox-master.zip https://github.com/mlperf/mlbox/archive/master.zip unzip mlbox-master.zip -d mlbox rm -r mlbox-master.zip cd mlbox Git Clone \u00b6 You can clone the MLBox project using Git git clone https://github.com/mlperf/mlbox.git cd mlbox Installing \u00b6 After downloading or cloning, from the root of the project directory you can install: pip install . To uninstall: pip uninstall mlbox Running Locally \u00b6 Toy Implementation \u00b6 To run the toy implementation (aka \"fake model\"): Notice This is not yet fully implemented. This will print a docker command simliar to what will be run. cd mlbox python mlbox_run.py ../examples/fake_model:train/small_batch To override and specify different files: --log_file=/tmp/my_log_file Transformer Implementation \u00b6 To run the transformer implementation: cd mlbox/ python mlbox_local_run.py ../examples/transformer:downloaddata/default python mlbox_local_run.py ../examples/transformer:preprocess/default python mlbox_local_run.py ../examples/transformer:train/default Usage Examples \u00b6 Check out the examples directory for detailed examples. License \u00b6 MLBox is licensed under the Apache License 2.0. See LICENSE for more information. Support \u00b6 Create a GitHub issue","title":"Home"},{"location":"#mlbox","text":"This is the MLBox \ud83d\udce6 Prototype.","title":"MLBox"},{"location":"#get-mlbox","text":"","title":"Get MLBox"},{"location":"#direct-download","text":"Directly download the project wget -O mlbox-master.zip https://github.com/mlperf/mlbox/archive/master.zip unzip mlbox-master.zip -d mlbox rm -r mlbox-master.zip cd mlbox","title":"Direct Download"},{"location":"#git-clone","text":"You can clone the MLBox project using Git git clone https://github.com/mlperf/mlbox.git cd mlbox","title":"Git Clone"},{"location":"#installing","text":"After downloading or cloning, from the root of the project directory you can install: pip install . To uninstall: pip uninstall mlbox","title":"Installing"},{"location":"#running-locally","text":"","title":"Running Locally"},{"location":"#toy-implementation","text":"To run the toy implementation (aka \"fake model\"): Notice This is not yet fully implemented. This will print a docker command simliar to what will be run. cd mlbox python mlbox_run.py ../examples/fake_model:train/small_batch To override and specify different files: --log_file=/tmp/my_log_file","title":"Toy Implementation"},{"location":"#transformer-implementation","text":"To run the transformer implementation: cd mlbox/ python mlbox_local_run.py ../examples/transformer:downloaddata/default python mlbox_local_run.py ../examples/transformer:preprocess/default python mlbox_local_run.py ../examples/transformer:train/default","title":"Transformer Implementation"},{"location":"#usage-examples","text":"Check out the examples directory for detailed examples.","title":"Usage Examples"},{"location":"#license","text":"MLBox is licensed under the Apache License 2.0. See LICENSE for more information.","title":"License"},{"location":"#support","text":"Create a GitHub issue","title":"Support"},{"location":"getting-started/","text":"Getting Started \u00b6","title":"Getting Started"},{"location":"getting-started/#getting-started","text":"","title":"Getting Started"},{"location":"getting-started/hello-world/","text":"Hello World \u00b6 Docker runtime \u00b6 Hello World MLCommons-Box is an example of a docker-based box. Docker runtime must be installed in a system. Installation guides for various operating systems can be found here . This example was tested on a system where users are in the docker group and run docker without sudo . To add yourself to a docker group, run the following: sudo groupadd docker # Add the docker group if it doesn't already exist. sudo gpasswd -a ${USER} docker # Add the connected user \"${USER}\" to the docker group. Change the user name to match your preferred user. sudo service docker restart # Restart the Docker daemon. newgrp docker # Either do a\u00c2 newgrp docker\u00c2 or log out/in to activate the changes to groups. Host python environment \u00b6 Hello World is an example of a simple python program distributed as an MLCommons-Box. This tutorial covers the case when the MLCommons-Box library and Hello World box are cloned from the GitHub repository: git clone https://github.com/mlperf/mlbox ./mlbox cd ./mlbox Python >= 3.6 is required together with runners' python dependencies: virtualenv -p python3.8 ./env source ./env/bin/activate pip install typer mlspeclib export PYTHONPATH=$(pwd)/mlcommons_box:$(pwd)/runners/mlcommons_box_singularity:$(pwd)/runners/mlcommons_box_docker:$(pwd)/runners/mlcommons_box_ssh Optionally, setup host environment by providing the correct http_proxy and https_proxy environmental variables. export http_proxy=... export https_proxy=... Configuring Hello World MLCommons-Box \u00b6 Boxes need to be configured before they can run. To do so, users need to run a MLCommons-Box runner with configure command providing path to a box root directory and path to a platform configuration file. The Hello World box is a docker-based box, so users provide path to a MLCommons-Box Docker platform configuration file that sets a number of parameters, including docker image name: python -m mlcommons_box_docker configure --mlbox=examples/hello_world --platform=examples/hello_world/platforms/docker.yaml The Docker runner will build a docker image for the Hello World box. Running Hello World MLCommons-Box \u00b6 In order to run the Hello World box, users need to provide the path to the root directory of the box, platform configuration file and path to a task definition file. Run the following two commands one at a time: python -m mlcommons_box_docker run --mlbox=examples/hello_world --platform=examples/hello_world/platforms/docker.yaml --task=examples/hello_world/run/alice/hello.yaml python -m mlcommons_box_docker run --mlbox=examples/hello_world --platform=examples/hello_world/platforms/docker.yaml --task=examples/hello_world/run/alice/bye.yaml Hello World creates a file examples/hello_world/workspace/chats/chat_with_alice.txt that contains the following: [2020-09-03 09:13:14.236945] Hi, Alice! Nice to meet you. [2020-09-03 09:13:20.749831] Bye, Alice! It was great talking to you. Modifying MLCommons-Box \u00b6 Adding new user \u00b6 Create a new file examples/hello_world/workspace/names/donald.txt with the following content: Donald . Create a new file examples/hello_world/run/donald/hello.yaml with the following content: schema_type : mlbox_invoke schema_version : 1.0.0 task_name : hello input_binding : name : $WORKSPACE/names/donald.txt output_binding : chat : $WORKSPACE/chats/chat_with_donald.txt Create a new file examples/hello_world/run/donald/bye.yaml with the following content: schema_type : mlbox_invoke schema_version : 1.0.0 task_name : bye input_binding : name : $WORKSPACE/names/donald.txt output_binding : chat : $WORKSPACE/chats/chat_with_donald.txt Run the following two commands one at a time: python -m mlcommons_box_docker run --mlbox=examples/hello_world --platform=examples/hello_world/platforms/docker.yaml --task=examples/hello_world/run/donald/hello.yaml python -m mlcommons_box_docker run --mlbox=examples/hello_world --platform=examples/hello_world/platforms/docker.yaml --task=examples/hello_world/run/donald/bye.yaml The Hello World box creates a file examples/hello_world/workspace/chats/chat_with_donald.txt that contains the following: [2020-09-03 09:23:09.569558] Hi, Donald! Nice to meet you. [2020-09-03 09:23:20.076845] Bye, Donald! It was great talking to you. Providing a better greeting message \u00b6 Because how Hello World box was implemented, the greeting message is always the following: Nice to meet you. . We will update the implementation so that if this is not the first time Alice says hello , the MLBox will respond: Nice to see you again. . Modify the file examples/hello_world/build/hello_world.py . Update the function named get_greeting_message on line 14. It should have the following implementation: def get_greeting_message ( chat_file : str ) -> str : return \"Nice to meet you.\" if not os . path . exists ( chat_file ) else \"Nice to see you again.\" Since we updated a file in the build subdirectory, we need to re-configure the Hello World box: python -m mlcommons_box_docker configure --mlbox=examples/hello_world --platform=examples/hello_world/platforms/docker.yaml Now, run two hello task again: python -m mlcommons_box_docker run --mlbox=examples/hello_world --platform=examples/hello_world/platforms/docker.yaml --task=examples/hello_world/run/alice/hello.yaml The MLBox recognized it was not the first time it talked to Alice, and changed the greeting: [2020-09-03 09:13:14.236945] Hi, Alice! Nice to meet you. [2020-09-03 09:13:20.749831] Bye, Alice! It was great talking to you. [2020-09-03 09:32:41.369367] Hi, Alice! Nice to see you again.","title":"Hello World"},{"location":"getting-started/hello-world/#hello-world","text":"","title":"Hello World"},{"location":"getting-started/hello-world/#docker-runtime","text":"Hello World MLCommons-Box is an example of a docker-based box. Docker runtime must be installed in a system. Installation guides for various operating systems can be found here . This example was tested on a system where users are in the docker group and run docker without sudo . To add yourself to a docker group, run the following: sudo groupadd docker # Add the docker group if it doesn't already exist. sudo gpasswd -a ${USER} docker # Add the connected user \"${USER}\" to the docker group. Change the user name to match your preferred user. sudo service docker restart # Restart the Docker daemon. newgrp docker # Either do a\u00c2 newgrp docker\u00c2 or log out/in to activate the changes to groups.","title":"Docker runtime"},{"location":"getting-started/hello-world/#host-python-environment","text":"Hello World is an example of a simple python program distributed as an MLCommons-Box. This tutorial covers the case when the MLCommons-Box library and Hello World box are cloned from the GitHub repository: git clone https://github.com/mlperf/mlbox ./mlbox cd ./mlbox Python >= 3.6 is required together with runners' python dependencies: virtualenv -p python3.8 ./env source ./env/bin/activate pip install typer mlspeclib export PYTHONPATH=$(pwd)/mlcommons_box:$(pwd)/runners/mlcommons_box_singularity:$(pwd)/runners/mlcommons_box_docker:$(pwd)/runners/mlcommons_box_ssh Optionally, setup host environment by providing the correct http_proxy and https_proxy environmental variables. export http_proxy=... export https_proxy=...","title":"Host python environment"},{"location":"getting-started/hello-world/#configuring-hello-world-mlcommons-box","text":"Boxes need to be configured before they can run. To do so, users need to run a MLCommons-Box runner with configure command providing path to a box root directory and path to a platform configuration file. The Hello World box is a docker-based box, so users provide path to a MLCommons-Box Docker platform configuration file that sets a number of parameters, including docker image name: python -m mlcommons_box_docker configure --mlbox=examples/hello_world --platform=examples/hello_world/platforms/docker.yaml The Docker runner will build a docker image for the Hello World box.","title":"Configuring Hello World MLCommons-Box"},{"location":"getting-started/hello-world/#running-hello-world-mlcommons-box","text":"In order to run the Hello World box, users need to provide the path to the root directory of the box, platform configuration file and path to a task definition file. Run the following two commands one at a time: python -m mlcommons_box_docker run --mlbox=examples/hello_world --platform=examples/hello_world/platforms/docker.yaml --task=examples/hello_world/run/alice/hello.yaml python -m mlcommons_box_docker run --mlbox=examples/hello_world --platform=examples/hello_world/platforms/docker.yaml --task=examples/hello_world/run/alice/bye.yaml Hello World creates a file examples/hello_world/workspace/chats/chat_with_alice.txt that contains the following: [2020-09-03 09:13:14.236945] Hi, Alice! Nice to meet you. [2020-09-03 09:13:20.749831] Bye, Alice! It was great talking to you.","title":"Running Hello World MLCommons-Box"},{"location":"getting-started/hello-world/#modifying-mlcommons-box","text":"","title":"Modifying MLCommons-Box"},{"location":"getting-started/hello-world/#adding-new-user","text":"Create a new file examples/hello_world/workspace/names/donald.txt with the following content: Donald . Create a new file examples/hello_world/run/donald/hello.yaml with the following content: schema_type : mlbox_invoke schema_version : 1.0.0 task_name : hello input_binding : name : $WORKSPACE/names/donald.txt output_binding : chat : $WORKSPACE/chats/chat_with_donald.txt Create a new file examples/hello_world/run/donald/bye.yaml with the following content: schema_type : mlbox_invoke schema_version : 1.0.0 task_name : bye input_binding : name : $WORKSPACE/names/donald.txt output_binding : chat : $WORKSPACE/chats/chat_with_donald.txt Run the following two commands one at a time: python -m mlcommons_box_docker run --mlbox=examples/hello_world --platform=examples/hello_world/platforms/docker.yaml --task=examples/hello_world/run/donald/hello.yaml python -m mlcommons_box_docker run --mlbox=examples/hello_world --platform=examples/hello_world/platforms/docker.yaml --task=examples/hello_world/run/donald/bye.yaml The Hello World box creates a file examples/hello_world/workspace/chats/chat_with_donald.txt that contains the following: [2020-09-03 09:23:09.569558] Hi, Donald! Nice to meet you. [2020-09-03 09:23:20.076845] Bye, Donald! It was great talking to you.","title":"Adding new user"},{"location":"getting-started/hello-world/#providing-a-better-greeting-message","text":"Because how Hello World box was implemented, the greeting message is always the following: Nice to meet you. . We will update the implementation so that if this is not the first time Alice says hello , the MLBox will respond: Nice to see you again. . Modify the file examples/hello_world/build/hello_world.py . Update the function named get_greeting_message on line 14. It should have the following implementation: def get_greeting_message ( chat_file : str ) -> str : return \"Nice to meet you.\" if not os . path . exists ( chat_file ) else \"Nice to see you again.\" Since we updated a file in the build subdirectory, we need to re-configure the Hello World box: python -m mlcommons_box_docker configure --mlbox=examples/hello_world --platform=examples/hello_world/platforms/docker.yaml Now, run two hello task again: python -m mlcommons_box_docker run --mlbox=examples/hello_world --platform=examples/hello_world/platforms/docker.yaml --task=examples/hello_world/run/alice/hello.yaml The MLBox recognized it was not the first time it talked to Alice, and changed the greeting: [2020-09-03 09:13:14.236945] Hi, Alice! Nice to meet you. [2020-09-03 09:13:20.749831] Bye, Alice! It was great talking to you. [2020-09-03 09:32:41.369367] Hi, Alice! Nice to see you again.","title":"Providing a better greeting message"},{"location":"getting-started/mnist/","text":"MNIST \u00b6 The MNIST dataset is a collection of 60,000 handwritten digits widely used for training statistical, Machine Learning (ML) and Deep Learning (DL) models. The MNIST MLCommons-Box example demonstrates how data scientists, ML and DL researchers and developers can distribute their ML projects (including training, validation and inference code) as MLCommons-Box boxes. MLCommons-Box establishes a standard to package user workloads, and provides unified command line interface. In addition, MLCommons-Box provides a number of reference runners - python packages that can run boxes on different platforms including docker and singularity. A data scientist has been working on a machine learning project. The goal is to train a simple neural network to classify collection of 60,000 small images into 10 classes. MNIST training code \u00b6 Training a ML model is a process involving multiple steps such as getting data, analyzing and cleaning data, splitting into train/validation/test data sets, running hyper-parameter optimization experiments and performing final model testing. It is a relatively small and well studied dataset that provides standard train/test split. In this simple example a developer needs to implement two steps - (1) downloading data and (2) training a model. We'll call these steps as tasks . Each task requires several parameters, such as URL of the data set that we need to download, location on a local disk where the data set will be serialized, path to a directory that will contain training artifacts such as log files, training snapshots and ML models. We can characterize these two tasks in the following way: - Data Download task: - Inputs : None. We'll assume the download URL is defined in the source code. - Outputs : Directory to serialize the data set ( data_dir ) and directory to serialize log files ( log_dir ). - Training task: - Inputs : Directory with MNIST data set ( data_dir ), training hyper-parameters defined in a file ( parameters_file ). - Outputs : Directory to store training results ( model_dir ) and directory to store log files ( log_dir ). We have intentionally made all input/output parameters to be file system artifacts. By doing so, we support reproducibility. Instead of command line arguments that can easily be lost, we store them in files. There are many different ways to implement the MNIST example. For simplicity, we assume the following: - We use one python file. - Task name (download, train) is a command line positional parameter. - Both tasks write logs, so it makes sense to add parameter accepting directory for log files. - The download task accepts additional data directory parameter. - The train task accepts such parameters as data and model directories, path to a file with hyper-parameter. - Configurable hyper-parameters are: (1) optimizer name, (2) number of training epochs and (3) global batch size. Then, our implementation could look like this. Parse command line and identify task. If it is download , call a function that downloads data sets. If it is train , train a model. This is sort of single entrypoint implementation where we run one script asking to perform various tasks. We run our script (mnist.py) in the following way: python mnist.py download --data_dir=PATH --log_dir=PATH python mnist.py train --data_dir=PATH --log_dir=PATH --model_dir=PATH --parameters_file=PATH MLCommons-Box implementation \u00b6 Packaging our MNIST training script as a MLCommons-Box is done in several steps. We will be using a directory-based box where a directory is structured in a certain way and contains specific files that make it MLCommons-Box compliant. We need to create an empty directory on a local disk. Let's assume we call it mnist and we'll use {MLCOMMONS_BOX_ROOT} to denote a full path to this directory. This is called a box root directory. At this point this directory is empty: mnist/ Build location \u00b6 The box directory has a sub-directory called build ( {MLCOMMONS_BOX_ROOT}/build ) that stores project source files, resources required for training, other files to recreate run time (such as requirements.txt, docker and singularity recipes etc.). We need to create the build directory and copy two files: mnist.py that implements training and requirements.txt that lists python dependencies. By doing so, we are enforcing reproducibility. A developer of this box wants to make it easier to run their training workload in a great variety of environments including universities, commercial companies, HPC-friendly organizations such as national labs. One way to achieve it is to use container runtime such as docker or singularity. So, we'll provide both docker file and singularity recipe that we'll put into build directory as well. Thus, we'll make this directory a build context. The box directory now looks like: mnist/ build/ mnist.py requirements.txt Dockerfile Singularity.recipe A good test at this point would be ensure that project is runnable from the build directory, and docker and singularity images can be built. MLCommons-Box definition file \u00b6 At this point we are ready to create a box definition file. This is the first definition file that makes some folder a MLCommons-Box folder. This is a YAML file that provides information such as name, author, version, named as mlbox.yaml and located in the box root directory . The most important section is the one that lists what tasks are implemented in this box: schema_version : 1.0.0 # We use MLSpec library to validate YAML definition files. This is the schema_type : mlbox_root # specification of the schema that this file must be consistent with. name : mnist # Name of this box. author : MLPerf Best Practices Working Group # A developer of the box. version : 0.1.0 # MLBox version. mlbox_spec_version : 0.1.0 # TODO: What is it? tasks : # Tasks are defined in external YAML files located in tasks folder. - 'tasks/download.yaml' # \"Download data set\" task definition file. - 'tasks/train.yaml' # \"Training a model\" task definition file. At this point, the directory looks like: mnist/ build/ {mnist.py, requirements.txt, Dockerfile, Singularity.recipe} mlbox.yaml Task definition file \u00b6 The box definition file references two tasks defined in the tasks subdirectory. Each YAML file there defines a task supported by the box. Task files are named the same as tasks. We need to create a tasks directory and two files inside that directory - download.yaml and train.yaml . Each task file defines input and output specifications for each task. The download task (download.yaml) is defined: schema_version : 1.0.0 # Task schema definition. Leave this two fields as is. schema_type : mlbox_task inputs : [] # Since this task does not have any inputs, the section is empty. outputs : # This task produces two artifacts - downloaded data and log files. - name : data_dir # This parameter accepts path to a directory where data set will be serialized. type : directory # We implicitly specify that this is a directory - name : log_dir # This parameter accepts path to a directory with log files this task writes. type : directory # We implicitly specify that this is a directory Names of these parameters are the same that are accepted by mnist.py: python mnist.py download --data_dir=PATH --log_dir=PATH The train task ( train.yaml ) is defined in the following way: schema_version : 1.0.0 # Task schema definition. Leave this two fields as is. schema_type : mlbox_task inputs : # These are the task inputs. - name : data_dir # This parameter accepts path to a directory where data set will be serialized. type : directory # We implicitly specify that this is a directory - name : parameters_file # A file containing training hyper-parameters. type : file # This is a file. outputs : # These are the task outputs. - name : log_dir # This parameter accepts path to a directory with log files this task writes. type : directory # We implicitly specify that this is a directory - name : model_dir # Path to a directory where training artifacts are stored. type : directory # We implicitly specify that this is a directory Names of these parameters are the same that are accepted by mnist.py: python mnist.py train --data_dir=PATH --log_dir=PATH --model_dir=PATH --parameters_file=PATH At this point, the MLBox directory looks like: mnist/ build/ {mnist.py, requirements.txt, Dockerfile, Singularity.recipe} tasks/ {download.yaml, train.yaml} mlbox.yaml Workspace \u00b6 The workspace is a directory inside box ( workspace ) where, by default, input/output file system artifacts are stored. The are multiple reasons to have one. One is to formally have default place for data sets, configuration and log files etc. Having all these parameters in one place makes it simpler to run boxes on remote hosts and then sync results back to users' local machines. We need to be able to provide collection of hyper-parameters and formally define a directory to store logs, models and MNIST data set. To do so, we create the directory tree workspace/parameters , and then create a file ( default.parameters.yaml ) with the following content: optimizer : \"adam\" train_epochs : 5 batch_size : 32 At this point, the box directory looks like: mnist/ build/ {mnist.py, requirements.txt, Dockerfile, Singularity.recipe} tasks/ {download.yaml, train.yaml} workspace/ parameters/ default.parameters.yaml mlbox.yaml Run configurations \u00b6 The MLCommons-Box definition file ( mlbox.yaml ) provides paths to task definition files that formally define tasks input/output parameters. A run configuration assigns values to task parameters. One reason to define and \"implement\" parameters in different files is to be able to provide multiple configurations for the same task. One example could be one-GPU training configuration and 8-GPU training configuration. Since we have two tasks - download and train - we need to define at least two run configurations. Run configurations are defined in the run subdirectory. Run configuration for the download task looks like: schema_type : mlbox_invoke # Run (invoke) schema definition. Leave this two fields as is. schema_version : 1.0.0 task_name : download # Task name input_binding : {} # No input parameters for this task. output_binding : # Output parameters, format is \"parameter: value\" data_dir : $WORKSPACE/data # Path to serialize downloaded MNIST data set log_dir : $WORKSPACE/download_logs # Path to log files. The $WORKSPACE token is replaced with actual path to the box workspace. File system paths are relative to the workspace directory. This makes it possible to provide absolute paths for cases when data sets are stored on shared drives. Run configuration for the train task looks like: schema_type : mlbox_invoke # Run (invoke) schema definition. Leave this two fields as is. schema_version : 1.0.0 task_name : train # Task name input_binding : # Input parameters (name: value) data_dir : $WORKSPACE/data parameters_file : $WORKSPACE/parameters/default.parameters.yaml output_binding : # Output parameters (name: value) log_dir : $WORKSPACE/train_logs model_dir : $WORKSPACE/model At this point, the box directory looks like: mnist/ build/ {mnist.py, requirements.txt, Dockerfile, Singularity.recipe} tasks/ {download.yaml, train.yaml} workspace/parameters/default.parameters.yaml run/ download.yaml train.yaml mlbox.yaml Platform configurations \u00b6 Platform configurations define how MLCommons-Box boxes run. Docker, Singularity, SSH and cloud runners have their own configurations. For instance, Docker platform configuration at minimum provides image name and docker executable (docker / nvidia-docker). SSH platform configuration could provide IP address of a remote host, login credentials etc. Platform configurations are supposed to be used by runners, and each runner has its own platform schema. The Runners documentation section provides detailed description of reference runners together with platform configuration schemas. Since we wanted to support Docker and Singularity runtimes, we provide docker.yaml and singularity.yaml files in the platforms subdirectory that is default location to store these types of files. Docker platform configuration is the following: schema_version : 1.0.0 schema_type : mlbox_docker image : mlperf/mlbox:mnist # Docker image name docker_runtime : docker # Docker executable: docker or nvidia-docker Singularity platform configuration is the following: schema_version : 1.0.0 schema_type : mlbox_singularity image : /opt/singularity/mlperf_mlbox_mnist-0.01.simg # Path to or name of a Singularity image. At this point, the box directory looks like: mnist/ build/ {mnist.py, requirements.txt, Dockerfile, Singularity.recipe} tasks/ {download.yaml, train.yaml} workspace/parameters/default.parameters.yaml run/ {download.yaml, train.yaml} platforms/ docker.yaml singularity.yaml mlbox.yaml MNIST MLCommons-Box directory structure summary \u00b6 mnist/ # MLBox root directory. build/ # Project source code, resource files, Docker/Singularity recipes. mnist.py # Python source code training simple neural network using MNIST data set. requirements.txt # Python project dependencies. Dockerfile # Docker recipe. Singularity.recipe # Singularity recipe. tasks/ # Task definition files - define functionality that MLBox supports download.yaml # Download MNIST data set. train.yaml # Train neural network. workspace/ # Default location for data sets, logs, models, parameter files. parameters/ # Model hyper-parameters can be stored at any location. default.parameters.yaml # This is just what is used in this implementation. run/ # Run configurations - bind task parameters and values. download.yaml # Concrete run specification for the download task. train.yaml # Concrete run specification for the train task. platforms/ # Platform definition files - define how MLBox runs. docker.yaml # Docker runtime definition. singularity.yaml # Singularity runtime definition. mlbox.yaml # MLBox definition file. Running MNIST MLCommons-Box \u00b6 This tutorial covers the case when both MLCommons-Box library and the MNIST box are cloned from the GitHub repository: git clone https://github.com/mlperf/mlbox ./mlbox cd ./mlbox Python >= 3.6 is required together with runners' python dependencies: virtualenv -p python3.8 ./env source ./env/bin/activate pip install typer mlspeclib export PYTHONPATH=$(pwd)/mlcommons_box:$(pwd)/runners/mlcommons_box_singularity:$(pwd)/runners/mlcommons_box_docker:$(pwd)/runners/mlcommons_box_ssh Optionally, setup host environment by providing the correct http_proxy and https_proxy environmental variables. export http_proxy=... export https_proxy=... Before running MNIST box below, it is probably a good idea to remove tasks' outputs from previous runs that are located in examples/mnist/workspace . All directories except parameters can be removed. Docker Runner \u00b6 Configure MNIST box: python -m mlcommons_box_docker configure --mlbox=examples/mnist --platform=examples/mnist/platforms/docker.yaml Run two tasks - download (download data) and train (train tiny neural network): python -m mlcommons_box_docker run --mlbox=examples/mnist --platform=examples/mnist/platforms/docker.yaml --task=examples/mnist/run/download.yaml python -m mlcommons_box_docker run --mlbox=examples/mnist --platform=examples/mnist/platforms/docker.yaml --task=examples/mnist/run/train.yaml Singularity Runner \u00b6 Update path to store Singularity image. Open examples/mnist/platforms/singularity.yaml and update the image value that is set by default to /opt/singularity/mlperf_mlbox_mnist-0.01.simg (relative paths are supported, they are relative to examples/mnist/workspace ). Configure MNIST box: python -m mlcommons_box_singularity configure --mlbox=examples/mnist --platform=examples/mnist/platforms/singularity.yaml Run two tasks - download (download data) and train (train tiny neural network): python -m mlcommons_box_singularity run --mlbox=examples/mnist --platform=examples/mnist/platforms/singularity.yaml --task=examples/mnist/run/download.yaml python -m mlcommons_box_singularity run --mlbox=examples/mnist --platform=examples/mnist/platforms/singularity.yaml --task=examples/mnist/run/train.yaml","title":"MNIST"},{"location":"getting-started/mnist/#mnist","text":"The MNIST dataset is a collection of 60,000 handwritten digits widely used for training statistical, Machine Learning (ML) and Deep Learning (DL) models. The MNIST MLCommons-Box example demonstrates how data scientists, ML and DL researchers and developers can distribute their ML projects (including training, validation and inference code) as MLCommons-Box boxes. MLCommons-Box establishes a standard to package user workloads, and provides unified command line interface. In addition, MLCommons-Box provides a number of reference runners - python packages that can run boxes on different platforms including docker and singularity. A data scientist has been working on a machine learning project. The goal is to train a simple neural network to classify collection of 60,000 small images into 10 classes.","title":"MNIST"},{"location":"getting-started/mnist/#mnist-training-code","text":"Training a ML model is a process involving multiple steps such as getting data, analyzing and cleaning data, splitting into train/validation/test data sets, running hyper-parameter optimization experiments and performing final model testing. It is a relatively small and well studied dataset that provides standard train/test split. In this simple example a developer needs to implement two steps - (1) downloading data and (2) training a model. We'll call these steps as tasks . Each task requires several parameters, such as URL of the data set that we need to download, location on a local disk where the data set will be serialized, path to a directory that will contain training artifacts such as log files, training snapshots and ML models. We can characterize these two tasks in the following way: - Data Download task: - Inputs : None. We'll assume the download URL is defined in the source code. - Outputs : Directory to serialize the data set ( data_dir ) and directory to serialize log files ( log_dir ). - Training task: - Inputs : Directory with MNIST data set ( data_dir ), training hyper-parameters defined in a file ( parameters_file ). - Outputs : Directory to store training results ( model_dir ) and directory to store log files ( log_dir ). We have intentionally made all input/output parameters to be file system artifacts. By doing so, we support reproducibility. Instead of command line arguments that can easily be lost, we store them in files. There are many different ways to implement the MNIST example. For simplicity, we assume the following: - We use one python file. - Task name (download, train) is a command line positional parameter. - Both tasks write logs, so it makes sense to add parameter accepting directory for log files. - The download task accepts additional data directory parameter. - The train task accepts such parameters as data and model directories, path to a file with hyper-parameter. - Configurable hyper-parameters are: (1) optimizer name, (2) number of training epochs and (3) global batch size. Then, our implementation could look like this. Parse command line and identify task. If it is download , call a function that downloads data sets. If it is train , train a model. This is sort of single entrypoint implementation where we run one script asking to perform various tasks. We run our script (mnist.py) in the following way: python mnist.py download --data_dir=PATH --log_dir=PATH python mnist.py train --data_dir=PATH --log_dir=PATH --model_dir=PATH --parameters_file=PATH","title":"MNIST training code"},{"location":"getting-started/mnist/#mlcommons-box-implementation","text":"Packaging our MNIST training script as a MLCommons-Box is done in several steps. We will be using a directory-based box where a directory is structured in a certain way and contains specific files that make it MLCommons-Box compliant. We need to create an empty directory on a local disk. Let's assume we call it mnist and we'll use {MLCOMMONS_BOX_ROOT} to denote a full path to this directory. This is called a box root directory. At this point this directory is empty: mnist/","title":"MLCommons-Box implementation"},{"location":"getting-started/mnist/#build-location","text":"The box directory has a sub-directory called build ( {MLCOMMONS_BOX_ROOT}/build ) that stores project source files, resources required for training, other files to recreate run time (such as requirements.txt, docker and singularity recipes etc.). We need to create the build directory and copy two files: mnist.py that implements training and requirements.txt that lists python dependencies. By doing so, we are enforcing reproducibility. A developer of this box wants to make it easier to run their training workload in a great variety of environments including universities, commercial companies, HPC-friendly organizations such as national labs. One way to achieve it is to use container runtime such as docker or singularity. So, we'll provide both docker file and singularity recipe that we'll put into build directory as well. Thus, we'll make this directory a build context. The box directory now looks like: mnist/ build/ mnist.py requirements.txt Dockerfile Singularity.recipe A good test at this point would be ensure that project is runnable from the build directory, and docker and singularity images can be built.","title":"Build location"},{"location":"getting-started/mnist/#mlcommons-box-definition-file","text":"At this point we are ready to create a box definition file. This is the first definition file that makes some folder a MLCommons-Box folder. This is a YAML file that provides information such as name, author, version, named as mlbox.yaml and located in the box root directory . The most important section is the one that lists what tasks are implemented in this box: schema_version : 1.0.0 # We use MLSpec library to validate YAML definition files. This is the schema_type : mlbox_root # specification of the schema that this file must be consistent with. name : mnist # Name of this box. author : MLPerf Best Practices Working Group # A developer of the box. version : 0.1.0 # MLBox version. mlbox_spec_version : 0.1.0 # TODO: What is it? tasks : # Tasks are defined in external YAML files located in tasks folder. - 'tasks/download.yaml' # \"Download data set\" task definition file. - 'tasks/train.yaml' # \"Training a model\" task definition file. At this point, the directory looks like: mnist/ build/ {mnist.py, requirements.txt, Dockerfile, Singularity.recipe} mlbox.yaml","title":"MLCommons-Box definition file"},{"location":"getting-started/mnist/#task-definition-file","text":"The box definition file references two tasks defined in the tasks subdirectory. Each YAML file there defines a task supported by the box. Task files are named the same as tasks. We need to create a tasks directory and two files inside that directory - download.yaml and train.yaml . Each task file defines input and output specifications for each task. The download task (download.yaml) is defined: schema_version : 1.0.0 # Task schema definition. Leave this two fields as is. schema_type : mlbox_task inputs : [] # Since this task does not have any inputs, the section is empty. outputs : # This task produces two artifacts - downloaded data and log files. - name : data_dir # This parameter accepts path to a directory where data set will be serialized. type : directory # We implicitly specify that this is a directory - name : log_dir # This parameter accepts path to a directory with log files this task writes. type : directory # We implicitly specify that this is a directory Names of these parameters are the same that are accepted by mnist.py: python mnist.py download --data_dir=PATH --log_dir=PATH The train task ( train.yaml ) is defined in the following way: schema_version : 1.0.0 # Task schema definition. Leave this two fields as is. schema_type : mlbox_task inputs : # These are the task inputs. - name : data_dir # This parameter accepts path to a directory where data set will be serialized. type : directory # We implicitly specify that this is a directory - name : parameters_file # A file containing training hyper-parameters. type : file # This is a file. outputs : # These are the task outputs. - name : log_dir # This parameter accepts path to a directory with log files this task writes. type : directory # We implicitly specify that this is a directory - name : model_dir # Path to a directory where training artifacts are stored. type : directory # We implicitly specify that this is a directory Names of these parameters are the same that are accepted by mnist.py: python mnist.py train --data_dir=PATH --log_dir=PATH --model_dir=PATH --parameters_file=PATH At this point, the MLBox directory looks like: mnist/ build/ {mnist.py, requirements.txt, Dockerfile, Singularity.recipe} tasks/ {download.yaml, train.yaml} mlbox.yaml","title":"Task definition file"},{"location":"getting-started/mnist/#workspace","text":"The workspace is a directory inside box ( workspace ) where, by default, input/output file system artifacts are stored. The are multiple reasons to have one. One is to formally have default place for data sets, configuration and log files etc. Having all these parameters in one place makes it simpler to run boxes on remote hosts and then sync results back to users' local machines. We need to be able to provide collection of hyper-parameters and formally define a directory to store logs, models and MNIST data set. To do so, we create the directory tree workspace/parameters , and then create a file ( default.parameters.yaml ) with the following content: optimizer : \"adam\" train_epochs : 5 batch_size : 32 At this point, the box directory looks like: mnist/ build/ {mnist.py, requirements.txt, Dockerfile, Singularity.recipe} tasks/ {download.yaml, train.yaml} workspace/ parameters/ default.parameters.yaml mlbox.yaml","title":"Workspace"},{"location":"getting-started/mnist/#run-configurations","text":"The MLCommons-Box definition file ( mlbox.yaml ) provides paths to task definition files that formally define tasks input/output parameters. A run configuration assigns values to task parameters. One reason to define and \"implement\" parameters in different files is to be able to provide multiple configurations for the same task. One example could be one-GPU training configuration and 8-GPU training configuration. Since we have two tasks - download and train - we need to define at least two run configurations. Run configurations are defined in the run subdirectory. Run configuration for the download task looks like: schema_type : mlbox_invoke # Run (invoke) schema definition. Leave this two fields as is. schema_version : 1.0.0 task_name : download # Task name input_binding : {} # No input parameters for this task. output_binding : # Output parameters, format is \"parameter: value\" data_dir : $WORKSPACE/data # Path to serialize downloaded MNIST data set log_dir : $WORKSPACE/download_logs # Path to log files. The $WORKSPACE token is replaced with actual path to the box workspace. File system paths are relative to the workspace directory. This makes it possible to provide absolute paths for cases when data sets are stored on shared drives. Run configuration for the train task looks like: schema_type : mlbox_invoke # Run (invoke) schema definition. Leave this two fields as is. schema_version : 1.0.0 task_name : train # Task name input_binding : # Input parameters (name: value) data_dir : $WORKSPACE/data parameters_file : $WORKSPACE/parameters/default.parameters.yaml output_binding : # Output parameters (name: value) log_dir : $WORKSPACE/train_logs model_dir : $WORKSPACE/model At this point, the box directory looks like: mnist/ build/ {mnist.py, requirements.txt, Dockerfile, Singularity.recipe} tasks/ {download.yaml, train.yaml} workspace/parameters/default.parameters.yaml run/ download.yaml train.yaml mlbox.yaml","title":"Run configurations"},{"location":"getting-started/mnist/#platform-configurations","text":"Platform configurations define how MLCommons-Box boxes run. Docker, Singularity, SSH and cloud runners have their own configurations. For instance, Docker platform configuration at minimum provides image name and docker executable (docker / nvidia-docker). SSH platform configuration could provide IP address of a remote host, login credentials etc. Platform configurations are supposed to be used by runners, and each runner has its own platform schema. The Runners documentation section provides detailed description of reference runners together with platform configuration schemas. Since we wanted to support Docker and Singularity runtimes, we provide docker.yaml and singularity.yaml files in the platforms subdirectory that is default location to store these types of files. Docker platform configuration is the following: schema_version : 1.0.0 schema_type : mlbox_docker image : mlperf/mlbox:mnist # Docker image name docker_runtime : docker # Docker executable: docker or nvidia-docker Singularity platform configuration is the following: schema_version : 1.0.0 schema_type : mlbox_singularity image : /opt/singularity/mlperf_mlbox_mnist-0.01.simg # Path to or name of a Singularity image. At this point, the box directory looks like: mnist/ build/ {mnist.py, requirements.txt, Dockerfile, Singularity.recipe} tasks/ {download.yaml, train.yaml} workspace/parameters/default.parameters.yaml run/ {download.yaml, train.yaml} platforms/ docker.yaml singularity.yaml mlbox.yaml","title":"Platform configurations"},{"location":"getting-started/mnist/#mnist-mlcommons-box-directory-structure-summary","text":"mnist/ # MLBox root directory. build/ # Project source code, resource files, Docker/Singularity recipes. mnist.py # Python source code training simple neural network using MNIST data set. requirements.txt # Python project dependencies. Dockerfile # Docker recipe. Singularity.recipe # Singularity recipe. tasks/ # Task definition files - define functionality that MLBox supports download.yaml # Download MNIST data set. train.yaml # Train neural network. workspace/ # Default location for data sets, logs, models, parameter files. parameters/ # Model hyper-parameters can be stored at any location. default.parameters.yaml # This is just what is used in this implementation. run/ # Run configurations - bind task parameters and values. download.yaml # Concrete run specification for the download task. train.yaml # Concrete run specification for the train task. platforms/ # Platform definition files - define how MLBox runs. docker.yaml # Docker runtime definition. singularity.yaml # Singularity runtime definition. mlbox.yaml # MLBox definition file.","title":"MNIST MLCommons-Box directory structure summary"},{"location":"getting-started/mnist/#running-mnist-mlcommons-box","text":"This tutorial covers the case when both MLCommons-Box library and the MNIST box are cloned from the GitHub repository: git clone https://github.com/mlperf/mlbox ./mlbox cd ./mlbox Python >= 3.6 is required together with runners' python dependencies: virtualenv -p python3.8 ./env source ./env/bin/activate pip install typer mlspeclib export PYTHONPATH=$(pwd)/mlcommons_box:$(pwd)/runners/mlcommons_box_singularity:$(pwd)/runners/mlcommons_box_docker:$(pwd)/runners/mlcommons_box_ssh Optionally, setup host environment by providing the correct http_proxy and https_proxy environmental variables. export http_proxy=... export https_proxy=... Before running MNIST box below, it is probably a good idea to remove tasks' outputs from previous runs that are located in examples/mnist/workspace . All directories except parameters can be removed.","title":"Running MNIST MLCommons-Box"},{"location":"getting-started/mnist/#docker-runner","text":"Configure MNIST box: python -m mlcommons_box_docker configure --mlbox=examples/mnist --platform=examples/mnist/platforms/docker.yaml Run two tasks - download (download data) and train (train tiny neural network): python -m mlcommons_box_docker run --mlbox=examples/mnist --platform=examples/mnist/platforms/docker.yaml --task=examples/mnist/run/download.yaml python -m mlcommons_box_docker run --mlbox=examples/mnist --platform=examples/mnist/platforms/docker.yaml --task=examples/mnist/run/train.yaml","title":"Docker Runner"},{"location":"getting-started/mnist/#singularity-runner","text":"Update path to store Singularity image. Open examples/mnist/platforms/singularity.yaml and update the image value that is set by default to /opt/singularity/mlperf_mlbox_mnist-0.01.simg (relative paths are supported, they are relative to examples/mnist/workspace ). Configure MNIST box: python -m mlcommons_box_singularity configure --mlbox=examples/mnist --platform=examples/mnist/platforms/singularity.yaml Run two tasks - download (download data) and train (train tiny neural network): python -m mlcommons_box_singularity run --mlbox=examples/mnist --platform=examples/mnist/platforms/singularity.yaml --task=examples/mnist/run/download.yaml python -m mlcommons_box_singularity run --mlbox=examples/mnist --platform=examples/mnist/platforms/singularity.yaml --task=examples/mnist/run/train.yaml","title":"Singularity Runner"},{"location":"runners/","text":"Runners \u00b6 A runner is a tool that runs MLCommons-Box boxes on one or multiple platforms. Examples of platforms are docker and singularity containers, remote hosts, virtual machines in the cloud, etc. A platform is configured in a platform configuration file. A box can provide reference platform configurations that users can modify to meet requirements of their infrastructures. MLCommons-Box standard requires that all runners implement mandatory functionality. All reference runners implement it. Users can develop their own runners to meet their specific requirements, such as security, authentication and authorization policies and others. Reference MLCommons-Box runners \u00b6 Reference runners are: - Docker Runner : Runs boxes using docker runtime. - Singularity Runner : Runs boxes using singularity runtime. - SSH Runner : Runs boxes on remote hosts. SSH Runner uses other runners, such as Docker or Singularity runners, to run boxes on remote hosts. Runner commands \u00b6 Each runner exposes mandatory and optional functionality through a set of commands. This is similar to, for instance, how Git implements its CLI ( git followed by a specific command such as checkout , pull , push etc). Mandatory MLCommons-Box runner commands are configure and run : - configure : Configure MLCommons-Box. Exact functionality depends on a runner type, but the goal is to ensure that a box is ready to run. The following are the examples of what can be done at configure phase: build docker or singularity container, create python virtual environment, allocate and configure virtual machine in the cloud, copy box to a remote host etc. Once configuration is successfully completed, it is assumed a runner can run that box. - run : Run tasks defined in MLCommons-Box. Reference runners recognize three parameters - mlbox, platform and task. - mlbox : Path to a box root directory. In future versions, this can be an URI with a specific protocol. Runners could support various MLCommons-Box implementations (excluding reference directory-based) such as docker/singularity containers, GitHub repositories, compressed archives and others. - platform : Path to a YAML-based platform configuration file. If not present, a runner should use the default platforms to run a box, or select the most appropriate or available in a user environment. - task : Path to a YAML-based task specification file. If not present, a runner can run the default task. Command line interface \u00b6 One way to run a MLCommons-Box is to follow the following template supported by all reference runners: python -m RUNNER_PACKAGE --mlbox=MLCOMMONS_BOX_ROOT_DIRECTORY --platform=PLATFORM_FILE_PATH --task=TASK_FILE_PATH Example command to configure MNIST Docker-based MLCommons-Box: python -m mlbox_docker configure --mlbox=examples/mnist --platform=examples/mnist/platform/docker.yaml Example command to run two tasks implemented by the MNIST Docker-based MLCommons-Box: python -m mlbox_docker run --mlbox=examples/mnist --platform=examples/mnist/platform/docker.yaml --task=examples/mnist/run/download.yaml python -m mlbox_docker run --mlbox=examples/mnist --platform=examples/mnist/platform/docker.yaml --task=examples/mnist/run/train.yaml","title":"Runners"},{"location":"runners/#runners","text":"A runner is a tool that runs MLCommons-Box boxes on one or multiple platforms. Examples of platforms are docker and singularity containers, remote hosts, virtual machines in the cloud, etc. A platform is configured in a platform configuration file. A box can provide reference platform configurations that users can modify to meet requirements of their infrastructures. MLCommons-Box standard requires that all runners implement mandatory functionality. All reference runners implement it. Users can develop their own runners to meet their specific requirements, such as security, authentication and authorization policies and others.","title":"Runners"},{"location":"runners/#reference-mlcommons-box-runners","text":"Reference runners are: - Docker Runner : Runs boxes using docker runtime. - Singularity Runner : Runs boxes using singularity runtime. - SSH Runner : Runs boxes on remote hosts. SSH Runner uses other runners, such as Docker or Singularity runners, to run boxes on remote hosts.","title":"Reference MLCommons-Box runners"},{"location":"runners/#runner-commands","text":"Each runner exposes mandatory and optional functionality through a set of commands. This is similar to, for instance, how Git implements its CLI ( git followed by a specific command such as checkout , pull , push etc). Mandatory MLCommons-Box runner commands are configure and run : - configure : Configure MLCommons-Box. Exact functionality depends on a runner type, but the goal is to ensure that a box is ready to run. The following are the examples of what can be done at configure phase: build docker or singularity container, create python virtual environment, allocate and configure virtual machine in the cloud, copy box to a remote host etc. Once configuration is successfully completed, it is assumed a runner can run that box. - run : Run tasks defined in MLCommons-Box. Reference runners recognize three parameters - mlbox, platform and task. - mlbox : Path to a box root directory. In future versions, this can be an URI with a specific protocol. Runners could support various MLCommons-Box implementations (excluding reference directory-based) such as docker/singularity containers, GitHub repositories, compressed archives and others. - platform : Path to a YAML-based platform configuration file. If not present, a runner should use the default platforms to run a box, or select the most appropriate or available in a user environment. - task : Path to a YAML-based task specification file. If not present, a runner can run the default task.","title":"Runner commands"},{"location":"runners/#command-line-interface","text":"One way to run a MLCommons-Box is to follow the following template supported by all reference runners: python -m RUNNER_PACKAGE --mlbox=MLCOMMONS_BOX_ROOT_DIRECTORY --platform=PLATFORM_FILE_PATH --task=TASK_FILE_PATH Example command to configure MNIST Docker-based MLCommons-Box: python -m mlbox_docker configure --mlbox=examples/mnist --platform=examples/mnist/platform/docker.yaml Example command to run two tasks implemented by the MNIST Docker-based MLCommons-Box: python -m mlbox_docker run --mlbox=examples/mnist --platform=examples/mnist/platform/docker.yaml --task=examples/mnist/run/download.yaml python -m mlbox_docker run --mlbox=examples/mnist --platform=examples/mnist/platform/docker.yaml --task=examples/mnist/run/train.yaml","title":"Command line interface"},{"location":"runners/docker-runner/","text":"Docker Runner \u00b6 Docker runner uses docker/nvidia-docker to run MLCommons-Box boxes. It supports two mandatory commands - configure and run with standard arguments - mlbox , platform and task . Docker platform configuration is used to configure docker runner. Platform Configuration File \u00b6 Docker platform configuration file is a YAML file that follows mlbox_docker ML schema. The configuration file for the reference MNIST box is the following: schema_version : 1.0.0 schema_type : mlbox_docker image : mlperf/mlbox:mnist # Docker image name docker_runtime : docker # Docker executable: docker or nvidia-docker Additional configuration \u00b6 In current implementation, Docker runner uses http_proxy and https_proxy environmental variables (if set) during configure and run phases: - configure : docker build ... --build-args http_proxy=${http_proxy} --build-args https_proxy=${https_proxy} ... - run : docker run ... -e http_proxy=${http_proxy} -e https_proxy=${https_proxy} ... Build command \u00b6 Docker runner uses {MLCOMMONS_BOX_ROOT}/build directory as the build context directory. This implies that all files that must be packaged in a docker image, must be located in that directory, including source files, python requirements, resource files, ML models etc. The docker recipe must have the standard name Dockerfile . In current implementation, only docker build is supported (i.e., Dockerfile must present). In future releases, Docker runner will support docker pull as well. Docker runner under the hood runs the following command line: cd {build_path}; docker build {env_args} -t {image_name} -f Dockerfile . where: - {build_path} is {MLCOMMONS_BOX_ROOT}/build root directory. - {env_args} is the arguments retrieved from user environment. Currently, only http_proxy and https_proxy are supported. - {image_name} is the image name defined in the platform configuration file. Run command \u00b6 Docker runner runs the following command: {docker_runtime} run --rm --net=host --privileged=true {volumes} {env_args} {image_name} {args} where: - {docker_exec} is the docker_runtime value from the Docker platform configuration file. - {volumes} are the mount points that the runner automatically constructs based upon the task input/output specifications. - {env_args} is the arguments retrieved from user environment, currently, only http_proxy and https_proxy are supported. - {image_name} is the image name from the platform configuration file. - {args} is the task command line arguments, constructed automatically by the runner.","title":"Docker Runner"},{"location":"runners/docker-runner/#docker-runner","text":"Docker runner uses docker/nvidia-docker to run MLCommons-Box boxes. It supports two mandatory commands - configure and run with standard arguments - mlbox , platform and task . Docker platform configuration is used to configure docker runner.","title":"Docker Runner"},{"location":"runners/docker-runner/#platform-configuration-file","text":"Docker platform configuration file is a YAML file that follows mlbox_docker ML schema. The configuration file for the reference MNIST box is the following: schema_version : 1.0.0 schema_type : mlbox_docker image : mlperf/mlbox:mnist # Docker image name docker_runtime : docker # Docker executable: docker or nvidia-docker","title":"Platform Configuration File"},{"location":"runners/docker-runner/#additional-configuration","text":"In current implementation, Docker runner uses http_proxy and https_proxy environmental variables (if set) during configure and run phases: - configure : docker build ... --build-args http_proxy=${http_proxy} --build-args https_proxy=${https_proxy} ... - run : docker run ... -e http_proxy=${http_proxy} -e https_proxy=${https_proxy} ...","title":"Additional configuration"},{"location":"runners/docker-runner/#build-command","text":"Docker runner uses {MLCOMMONS_BOX_ROOT}/build directory as the build context directory. This implies that all files that must be packaged in a docker image, must be located in that directory, including source files, python requirements, resource files, ML models etc. The docker recipe must have the standard name Dockerfile . In current implementation, only docker build is supported (i.e., Dockerfile must present). In future releases, Docker runner will support docker pull as well. Docker runner under the hood runs the following command line: cd {build_path}; docker build {env_args} -t {image_name} -f Dockerfile . where: - {build_path} is {MLCOMMONS_BOX_ROOT}/build root directory. - {env_args} is the arguments retrieved from user environment. Currently, only http_proxy and https_proxy are supported. - {image_name} is the image name defined in the platform configuration file.","title":"Build command"},{"location":"runners/docker-runner/#run-command","text":"Docker runner runs the following command: {docker_runtime} run --rm --net=host --privileged=true {volumes} {env_args} {image_name} {args} where: - {docker_exec} is the docker_runtime value from the Docker platform configuration file. - {volumes} are the mount points that the runner automatically constructs based upon the task input/output specifications. - {env_args} is the arguments retrieved from user environment, currently, only http_proxy and https_proxy are supported. - {image_name} is the image name from the platform configuration file. - {args} is the task command line arguments, constructed automatically by the runner.","title":"Run command"},{"location":"runners/singularity-runner/","text":"Singularity Runner \u00b6 Singularity runner uses singularity to run MLCommon-Box boxes. It supports two mandatory commands - configure and run with standard arguments - mlbox , platform and task . Singularity platform configuration is used to configure Singularity runner. Platform Configuration File \u00b6 Singularity platform configuration file is a YAML file that follows mlbox_singularity ML schema. The configuration file for the reference MNIST box is the following: schema_version : 1.0.0 schema_type : mlbox_singularity image : /opt/singularity/mlperf_mlbox_mnist-0.01.simg # Path to or name of a Singularity image. The image field above is a path to a singularity container. It is relative to {MLCOMMONS_BOX_ROOT}/workspace : - By default, containers are stored in {MLCOMMONS_BOX_ROOT}/workspace if image is a file name. - If it is a relative path, it is relative to {MLCOMMONS_BOX_ROOT}/workspace . - Absolute paths (starting with /) are used as is. In the example above, Singularity image is stored in the directory outside of the {MLCOMMONS_BOX_ROOT} to avoid copying it back to a user host when using runners such as SSH. Build command \u00b6 Singularity runner uses {MLCOMMONS_BOX_ROOT}/build directory as the build context directory. This implies that all files that must be packaged in a singularity image, must be located in that directory, including source files, python requirements, resource files, ML models etc. The singularity recipe must have the standard name Singularity.recipe . Singularity runner under the hood runs the following command line: cd {build_path}; singularity build --fakeroot {image_path} Singularity.recipe where: - {build_path} is {MLCOMMONS_BOX_ROOT}/build root directory. - {image_path} is the path to Singularity image that is computed as described above. Run command \u00b6 Singularity runner runs the following command: singularity run {volumes} {image_path} {args} where: - {volumes} are the mount points that the runner automatically constructs based upon the task input/output specifications. - {image_path} is the path to Singularity image that is computed as described above. - {args} is the task command line arguments, constructed automatically by the runner.","title":"Singularity Runner"},{"location":"runners/singularity-runner/#singularity-runner","text":"Singularity runner uses singularity to run MLCommon-Box boxes. It supports two mandatory commands - configure and run with standard arguments - mlbox , platform and task . Singularity platform configuration is used to configure Singularity runner.","title":"Singularity Runner"},{"location":"runners/singularity-runner/#platform-configuration-file","text":"Singularity platform configuration file is a YAML file that follows mlbox_singularity ML schema. The configuration file for the reference MNIST box is the following: schema_version : 1.0.0 schema_type : mlbox_singularity image : /opt/singularity/mlperf_mlbox_mnist-0.01.simg # Path to or name of a Singularity image. The image field above is a path to a singularity container. It is relative to {MLCOMMONS_BOX_ROOT}/workspace : - By default, containers are stored in {MLCOMMONS_BOX_ROOT}/workspace if image is a file name. - If it is a relative path, it is relative to {MLCOMMONS_BOX_ROOT}/workspace . - Absolute paths (starting with /) are used as is. In the example above, Singularity image is stored in the directory outside of the {MLCOMMONS_BOX_ROOT} to avoid copying it back to a user host when using runners such as SSH.","title":"Platform Configuration File"},{"location":"runners/singularity-runner/#build-command","text":"Singularity runner uses {MLCOMMONS_BOX_ROOT}/build directory as the build context directory. This implies that all files that must be packaged in a singularity image, must be located in that directory, including source files, python requirements, resource files, ML models etc. The singularity recipe must have the standard name Singularity.recipe . Singularity runner under the hood runs the following command line: cd {build_path}; singularity build --fakeroot {image_path} Singularity.recipe where: - {build_path} is {MLCOMMONS_BOX_ROOT}/build root directory. - {image_path} is the path to Singularity image that is computed as described above.","title":"Build command"},{"location":"runners/singularity-runner/#run-command","text":"Singularity runner runs the following command: singularity run {volumes} {image_path} {args} where: - {volumes} are the mount points that the runner automatically constructs based upon the task input/output specifications. - {image_path} is the path to Singularity image that is computed as described above. - {args} is the task command line arguments, constructed automatically by the runner.","title":"Run command"},{"location":"runners/ssh-runner/","text":"SSH Runner \u00b6 SSH runner uses other runners to run MLCommons-Box boxes on remote hosts. It uses ssh and rsync internally. It supports two mandatory commands - configure and run with standard arguments - mlbox , platform and task . SSH platform configuration is used to configure SSH runner. This runner is being actively developed and not all features described on this page may be supported. Platform Configuration File \u00b6 SSH platform configuration file is a YAML file. The configuration file for the reference MNIST box is the following: host : REMOTE_HOST # Remote host IP address. user : USER # User name, assuming passwordless authentication using keys has been set up. platform : docker.yaml # How to run this box on a remote host - use Docker Runner env : # This is for syncing MLBox library itself (library, runners etc.) path : ./mlbox # Path on a remote node, this is the default value. Relative paths are relative to use home dir. sync : true interpreter : # Host environment for runners, box can have its own interpreter. Dependencies must be installed. type : system python : python3.6 # Can also be an absolute path to user python environment (virtualenv, conda etc.) variables : {} # Environmental variables (will be used by docker build/run), remove '{}' if variables present. # http_proxy: # https_proxy: mlbox : # Remote location of the box to run path : # Null, the path will be set to ./.mlbox/mlboxes/mnist-${version} sync : true SSH runner uses IP or name of a remote host ( host ) and ssh tool to login and execute shell commands on remote hosts. It uses user name ( user ) for authentication. If passwordless login is not configured, SSH runner asks for password many times during configure and run phases. SSH runner depends on other runners to run MLCommons-Box boxes. The platform field specifies what runner should be used on a remote host. This is a file name relative to {MLCOMMONS_BOX_ROOT}/platforms . In current implementation, SSH runner synchronizes both MLCommons-Box library and a box workload between local and remote hosts. This is optional, and in the future versions, when the library and runners are installed using pip, this will not be required. Build command \u00b6 During the build phase, the following steps are performed. 1. If MLCommons-Box library (source tree) needs to be synchronized, SSH runner: - Uses ssh to create root directory for the library. - Uses rsync to synchronize the following library directories: mlcommons_box and runners . 2. If MLCommons-Box box needs to be synchronized, SSH runner: - Uses ssh to create root directory for the box on a remote host. - Uses rsync to synchronize the entire content of the box. 3. The only supported remote python environment is the system , and SSH runner assumes that all dependencies have been installed. Two required python packages that are not common are click and mlspeclib . 4. SSH runner uses platform file and runs standard configure command on a remote host. Run command \u00b6 During the run phase, the SSH runner performs the following steps: 1. It uses ssh to run standard run command on a remote host. 2. It uses rsync to synchronize back the content of the {MLCOMMONS_BOX_ROOT}/workspace directory.","title":"SSH Runner"},{"location":"runners/ssh-runner/#ssh-runner","text":"SSH runner uses other runners to run MLCommons-Box boxes on remote hosts. It uses ssh and rsync internally. It supports two mandatory commands - configure and run with standard arguments - mlbox , platform and task . SSH platform configuration is used to configure SSH runner. This runner is being actively developed and not all features described on this page may be supported.","title":"SSH Runner"},{"location":"runners/ssh-runner/#platform-configuration-file","text":"SSH platform configuration file is a YAML file. The configuration file for the reference MNIST box is the following: host : REMOTE_HOST # Remote host IP address. user : USER # User name, assuming passwordless authentication using keys has been set up. platform : docker.yaml # How to run this box on a remote host - use Docker Runner env : # This is for syncing MLBox library itself (library, runners etc.) path : ./mlbox # Path on a remote node, this is the default value. Relative paths are relative to use home dir. sync : true interpreter : # Host environment for runners, box can have its own interpreter. Dependencies must be installed. type : system python : python3.6 # Can also be an absolute path to user python environment (virtualenv, conda etc.) variables : {} # Environmental variables (will be used by docker build/run), remove '{}' if variables present. # http_proxy: # https_proxy: mlbox : # Remote location of the box to run path : # Null, the path will be set to ./.mlbox/mlboxes/mnist-${version} sync : true SSH runner uses IP or name of a remote host ( host ) and ssh tool to login and execute shell commands on remote hosts. It uses user name ( user ) for authentication. If passwordless login is not configured, SSH runner asks for password many times during configure and run phases. SSH runner depends on other runners to run MLCommons-Box boxes. The platform field specifies what runner should be used on a remote host. This is a file name relative to {MLCOMMONS_BOX_ROOT}/platforms . In current implementation, SSH runner synchronizes both MLCommons-Box library and a box workload between local and remote hosts. This is optional, and in the future versions, when the library and runners are installed using pip, this will not be required.","title":"Platform Configuration File"},{"location":"runners/ssh-runner/#build-command","text":"During the build phase, the following steps are performed. 1. If MLCommons-Box library (source tree) needs to be synchronized, SSH runner: - Uses ssh to create root directory for the library. - Uses rsync to synchronize the following library directories: mlcommons_box and runners . 2. If MLCommons-Box box needs to be synchronized, SSH runner: - Uses ssh to create root directory for the box on a remote host. - Uses rsync to synchronize the entire content of the box. 3. The only supported remote python environment is the system , and SSH runner assumes that all dependencies have been installed. Two required python packages that are not common are click and mlspeclib . 4. SSH runner uses platform file and runs standard configure command on a remote host.","title":"Build command"},{"location":"runners/ssh-runner/#run-command","text":"During the run phase, the SSH runner performs the following steps: 1. It uses ssh to run standard run command on a remote host. 2. It uses rsync to synchronize back the content of the {MLCOMMONS_BOX_ROOT}/workspace directory.","title":"Run command"}]}